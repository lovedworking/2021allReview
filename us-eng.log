2019-10-20 18:10:35[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-10-20 18:10:35[ERROR](Logging.scala:91) Error initializing SparkContext.
org.apache.spark.SparkException: A master URL must be set in your configuration
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:368)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:926)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
	at SparkSchema$.main(SparkSchema.scala:9)
	at SparkSchema.main(SparkSchema.scala)
2019-10-20 18:10:35[ERROR](Logging.scala:91) Uncaught exception in thread main
java.lang.NullPointerException
	at org.apache.spark.SparkContext.org$apache$spark$SparkContext$$postApplicationEnd(SparkContext.scala:2416)
	at org.apache.spark.SparkContext$$anonfun$stop$1.apply$mcV$sp(SparkContext.scala:1931)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1340)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1930)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:585)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2520)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:935)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:926)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:926)
	at SparkSchema$.main(SparkSchema.scala:9)
	at SparkSchema.main(SparkSchema.scala)
2019-10-20 18:10:35[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-10-22 15:46:38[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-10-22 15:46:39[ INFO](Logging.scala:54) Submitted application: reproduce
2019-10-22 15:46:39[ INFO](Logging.scala:54) Changing view acls to: Token
2019-10-22 15:46:39[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-10-22 15:46:39[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-10-22 15:46:39[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-10-22 15:46:39[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-10-22 15:46:41[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 62685.
2019-10-22 15:46:41[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-10-22 15:46:41[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-10-22 15:46:41[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-22 15:46:41[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-10-22 15:46:42[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-3c4c86a5-6537-4d45-aada-42c85767482f
2019-10-22 15:46:42[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-10-22 15:46:42[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-10-22 15:46:42[ INFO](Log.java:192) Logging initialized @7715ms
2019-10-22 15:46:42[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-10-22 15:46:42[ INFO](Server.java:419) Started @7777ms
2019-10-22 15:46:42[ INFO](AbstractConnector.java:278) Started ServerConnector@2b62442c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-22 15:46:42[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@64bc21ac{/jobs,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5118388b{/jobs/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@15a902e7{/jobs/job,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5af28b27{/stages,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@71104a4{/stages/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4985cbcb{/stages/stage,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@332a7fce{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@549621f3{/stages/pool,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@54361a9{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@32232e55{/storage,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5217f3d0{/storage/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@37ebc9d8{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@293bb8a5{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2416a51{/environment,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6fa590ba{/environment/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e9319f{/executors,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@72e34f77{/executors/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bf9b098{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@389adf1d{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@77307458{/static,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/api,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-22 15:46:42[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-10-22 15:46:42[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-10-22 15:46:42[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62698.
2019-10-22 15:46:42[ INFO](Logging.scala:54) Server created on TKK-YXKJ:62698
2019-10-22 15:46:42[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-22 15:46:42[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 62698, None)
2019-10-22 15:46:42[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:62698 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 62698, None)
2019-10-22 15:46:42[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 62698, None)
2019-10-22 15:46:42[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 62698, None)
2019-10-22 15:46:42[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bd81830{/metrics/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-10-22 15:46:44[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-10-22 15:46:44[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@39da5e49{/SQL,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2443abd6{/SQL/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5934ca1e{/SQL/execution,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5348d83c{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@d3e3085{/static/sql,null,AVAILABLE,@Spark}
2019-10-22 15:46:44[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-10-22 15:46:45[ INFO](Logging.scala:54) Cleaned accumulator 0
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 299.0222 ms
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 31.5045 ms
2019-10-22 15:46:45[ INFO](Logging.scala:54) Starting job: foreachPartition at Reproduce.scala:23
2019-10-22 15:46:45[ INFO](Logging.scala:54) Registering RDD 3 (foreachPartition at Reproduce.scala:23)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Got job 0 (foreachPartition at Reproduce.scala:23) with 200 output partitions
2019-10-22 15:46:45[ INFO](Logging.scala:54) Final stage: ResultStage 1 (foreachPartition at Reproduce.scala:23)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 0)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 0)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at foreachPartition at Reproduce.scala:23), which has no missing parents
2019-10-22 15:46:45[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 21.4 KB, free 896.4 MB)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.7 KB, free 896.4 MB)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:62698 (size: 9.7 KB, free: 896.4 MB)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Created broadcast 0 from broadcast at DAGScheduler.scala:1161
2019-10-22 15:46:45[ INFO](Logging.scala:54) Submitting 1 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at foreachPartition at Reproduce.scala:23) (first 15 tasks are for partitions Vector(0))
2019-10-22 15:46:45[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-10-22 15:46:45[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7786 bytes)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 7.4516 ms
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 6.5664 ms
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 6.3837 ms
2019-10-22 15:46:45[ INFO](Logging.scala:54) Code generated in 10.9251 ms
2019-10-22 15:46:46[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 2066 bytes result sent to driver
2019-10-22 15:46:46[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 254 ms on localhost (executor driver) (1/1)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-10-22 15:46:46[ INFO](Logging.scala:54) ShuffleMapStage 0 (foreachPartition at Reproduce.scala:23) finished in 0.379 s
2019-10-22 15:46:46[ INFO](Logging.scala:54) looking for newly runnable stages
2019-10-22 15:46:46[ INFO](Logging.scala:54) running: Set()
2019-10-22 15:46:46[ INFO](Logging.scala:54) waiting: Set(ResultStage 1)
2019-10-22 15:46:46[ INFO](Logging.scala:54) failed: Set()
2019-10-22 15:46:46[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at foreachPartition at Reproduce.scala:23), which has no missing parents
2019-10-22 15:46:46[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 19.7 KB, free 896.4 MB)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 9.7 KB, free 896.3 MB)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:62698 (size: 9.7 KB, free: 896.4 MB)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-10-22 15:46:46[ INFO](Logging.scala:54) Submitting 200 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at foreachPartition at Reproduce.scala:23) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2019-10-22 15:46:46[ INFO](Logging.scala:54) Adding task set 1.0 with 200 tasks
2019-10-22 15:46:46[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 7767 bytes)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2019-10-22 15:46:46[ INFO](Logging.scala:54) Started 0 remote fetches in 5 ms
2019-10-22 15:46:46[ INFO](Logging.scala:54) Code generated in 5.7768 ms
2019-10-22 15:46:46[ERROR](Logging.scala:91) Exception in task 0.0 in stage 1.0 (TID 1)
java.lang.NullPointerException
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.finishAggregate(HashAggregateExec.scala:368)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:732)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:708)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toVector(TraversableOnce.scala:306)
	at scala.collection.AbstractIterator.toVector(Iterator.scala:1334)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 2)
2019-10-22 15:46:46[ WARN](Logging.scala:66) Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.NullPointerException
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.finishAggregate(HashAggregateExec.scala:368)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:732)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:708)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toVector(TraversableOnce.scala:306)
	at scala.collection.AbstractIterator.toVector(Iterator.scala:1334)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

2019-10-22 15:46:46[ERROR](Logging.scala:70) Task 0 in stage 1.0 failed 1 times; aborting job
2019-10-22 15:46:46[ INFO](Logging.scala:54) Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2019-10-22 15:46:46[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-10-22 15:46:46[ INFO](Logging.scala:54) Cancelling stage 1
2019-10-22 15:46:46[ INFO](Logging.scala:54) Killing all running tasks in stage 1: Stage cancelled
2019-10-22 15:46:46[ERROR](Logging.scala:91) Exception in task 1.0 in stage 1.0 (TID 2)
java.lang.NullPointerException
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.finishAggregate(HashAggregateExec.scala:368)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:732)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:708)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toVector(TraversableOnce.scala:306)
	at scala.collection.AbstractIterator.toVector(Iterator.scala:1334)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2019-10-22 15:46:46[ INFO](Logging.scala:54) Stage 1 was cancelled
2019-10-22 15:46:46[ INFO](Logging.scala:54) ResultStage 1 (foreachPartition at Reproduce.scala:23) failed in 0.095 s due to Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost, executor driver): java.lang.NullPointerException
	at org.apache.spark.sql.execution.aggregate.HashAggregateExec.finishAggregate(HashAggregateExec.scala:368)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:732)
	at scala.collection.immutable.VectorBuilder.$plus$plus$eq(Vector.scala:708)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)
	at scala.collection.AbstractIterator.to(Iterator.scala:1334)
	at scala.collection.TraversableOnce$class.toVector(TraversableOnce.scala:306)
	at scala.collection.AbstractIterator.toVector(Iterator.scala:1334)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at testMulti.Reproduce$$anonfun$1$$anonfun$2.apply(Reproduce.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)

Driver stacktrace:
2019-10-22 15:46:46[ INFO](Logging.scala:54) Lost task 1.0 in stage 1.0 (TID 2) on localhost, executor driver: java.lang.NullPointerException (null) [duplicate 1]
2019-10-22 15:46:46[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-10-22 15:46:46[ INFO](Logging.scala:54) Job 0 failed: foreachPartition at Reproduce.scala:23, took 0.536141 s
2019-10-22 15:46:46[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-10-22 15:46:46[ INFO](AbstractConnector.java:318) Stopped Spark@2b62442c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-22 15:46:46[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-10-22 15:46:46[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-10-22 15:46:46[ INFO](Logging.scala:54) MemoryStore cleared
2019-10-22 15:46:46[ INFO](Logging.scala:54) BlockManager stopped
2019-10-22 15:46:46[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-10-22 15:46:46[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-10-22 15:46:46[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-10-22 15:46:46[ INFO](Logging.scala:54) Shutdown hook called
2019-10-22 15:46:46[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-8efc3d52-f6f2-495f-ae8f-79a5e2cc3e05
2019-10-23 15:19:34[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-10-23 15:19:34[ INFO](Logging.scala:54) Submitted application: testJson
2019-10-23 15:19:34[ INFO](Logging.scala:54) Changing view acls to: Token
2019-10-23 15:19:34[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-10-23 15:19:34[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-10-23 15:19:34[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-10-23 15:19:34[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-10-23 15:19:35[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 55501.
2019-10-23 15:19:35[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-10-23 15:19:35[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-10-23 15:19:35[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 15:19:35[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-10-23 15:19:36[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-630b69e4-4756-426c-b4bc-baa8cc49ad6e
2019-10-23 15:19:36[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-10-23 15:19:36[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-10-23 15:19:36[ INFO](Log.java:192) Logging initialized @22318ms
2019-10-23 15:19:36[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-10-23 15:19:36[ INFO](Server.java:419) Started @22383ms
2019-10-23 15:19:36[ INFO](AbstractConnector.java:278) Started ServerConnector@403132fc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 15:19:36[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/jobs,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@532a02d9{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@62923ee6{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4089713{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/environment,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@754777cd{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@50687efb{/,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@517bd097{/api,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@56e07a08{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@35d6ca49{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 15:19:36[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-10-23 15:19:36[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-10-23 15:19:36[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55543.
2019-10-23 15:19:36[ INFO](Logging.scala:54) Server created on TKK-YXKJ:55543
2019-10-23 15:19:36[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 15:19:36[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 55543, None)
2019-10-23 15:19:36[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:55543 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 55543, None)
2019-10-23 15:19:36[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 55543, None)
2019-10-23 15:19:36[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 55543, None)
2019-10-23 15:19:36[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@127d7908{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:37[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-10-23 15:19:37[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-10-23 15:19:37[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@297c9a9b{/SQL,null,AVAILABLE,@Spark}
2019-10-23 15:19:37[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@20999517{/SQL/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:37[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@479ac2cb{/SQL/execution,null,AVAILABLE,@Spark}
2019-10-23 15:19:37[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@220c9a63{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-10-23 15:19:37[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6c184d4d{/static/sql,null,AVAILABLE,@Spark}
2019-10-23 15:19:38[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-10-23 15:19:38[ INFO](Logging.scala:54) Code generated in 180.5967 ms
2019-10-23 15:19:39[ INFO](Logging.scala:54) Code generated in 6.6336 ms
2019-10-23 15:19:39[ INFO](Logging.scala:54) Starting job: json at TestJsonSource.java:29
2019-10-23 15:19:39[ INFO](Logging.scala:54) Got job 0 (json at TestJsonSource.java:29) with 1 output partitions
2019-10-23 15:19:39[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at TestJsonSource.java:29)
2019-10-23 15:19:39[ INFO](Logging.scala:54) Parents of final stage: List()
2019-10-23 15:19:39[ INFO](Logging.scala:54) Missing parents: List()
2019-10-23 15:19:39[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at TestJsonSource.java:29), which has no missing parents
2019-10-23 15:19:39[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 5.4 KB, free 896.4 MB)
2019-10-23 15:19:39[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 896.4 MB)
2019-10-23 15:19:39[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:55543 (size: 3.4 KB, free: 896.4 MB)
2019-10-23 15:19:39[ INFO](Logging.scala:54) Created broadcast 0 from broadcast at DAGScheduler.scala:1161
2019-10-23 15:19:39[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at TestJsonSource.java:29) (first 15 tasks are for partitions Vector(0))
2019-10-23 15:19:39[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-10-23 15:19:39[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8108 bytes)
2019-10-23 15:19:39[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1754 bytes result sent to driver
2019-10-23 15:19:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 60 ms on localhost (executor driver) (1/1)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-10-23 15:19:40[ INFO](Logging.scala:54) ResultStage 0 (json at TestJsonSource.java:29) finished in 0.836 s
2019-10-23 15:19:40[ INFO](Logging.scala:54) Job 0 finished: json at TestJsonSource.java:29, took 0.882511 s
2019-10-23 15:19:40[ INFO](Logging.scala:54) Code generated in 9.8475 ms
2019-10-23 15:19:40[ INFO](Logging.scala:54) Code generated in 11.5245 ms
2019-10-23 15:19:40[ INFO](Logging.scala:54) Starting job: show at TestJsonSource.java:30
2019-10-23 15:19:40[ INFO](Logging.scala:54) Got job 1 (show at TestJsonSource.java:30) with 1 output partitions
2019-10-23 15:19:40[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at TestJsonSource.java:30)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Parents of final stage: List()
2019-10-23 15:19:40[ INFO](Logging.scala:54) Missing parents: List()
2019-10-23 15:19:40[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[11] at show at TestJsonSource.java:30), which has no missing parents
2019-10-23 15:19:40[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 13.4 KB, free 896.4 MB)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.9 KB, free 896.4 MB)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:55543 (size: 6.9 KB, free: 896.4 MB)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-10-23 15:19:40[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at show at TestJsonSource.java:30) (first 15 tasks are for partitions Vector(0))
2019-10-23 15:19:40[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-10-23 15:19:40[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8108 bytes)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Code generated in 5.2758 ms
2019-10-23 15:19:40[ INFO](Logging.scala:54) Code generated in 7.6682 ms
2019-10-23 15:19:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1119 bytes result sent to driver
2019-10-23 15:19:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
2019-10-23 15:19:40[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-10-23 15:19:40[ INFO](Logging.scala:54) ResultStage 1 (show at TestJsonSource.java:30) finished in 0.060 s
2019-10-23 15:19:40[ INFO](Logging.scala:54) Job 1 finished: show at TestJsonSource.java:30, took 0.059000 s
2019-10-23 15:19:40[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-10-23 15:19:40[ INFO](AbstractConnector.java:318) Stopped Spark@403132fc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 15:19:40[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-10-23 15:19:40[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-10-23 15:19:40[ INFO](Logging.scala:54) MemoryStore cleared
2019-10-23 15:19:40[ INFO](Logging.scala:54) BlockManager stopped
2019-10-23 15:19:40[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-10-23 15:19:40[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-10-23 15:19:40[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-10-23 15:19:40[ INFO](Logging.scala:54) Shutdown hook called
2019-10-23 15:19:40[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-3f4d20f1-5442-4c29-b248-b9c054b8b7d3
2019-10-23 15:20:01[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-10-23 15:20:01[ INFO](Logging.scala:54) Submitted application: testJson
2019-10-23 15:20:01[ INFO](Logging.scala:54) Changing view acls to: Token
2019-10-23 15:20:01[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-10-23 15:20:01[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-10-23 15:20:01[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-10-23 15:20:01[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-10-23 15:20:03[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 55588.
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-10-23 15:20:03[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-10-23 15:20:03[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-10-23 15:20:03[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-8898a633-de3b-4da2-9a03-04796e21c22c
2019-10-23 15:20:03[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-10-23 15:20:03[ INFO](Log.java:192) Logging initialized @6472ms
2019-10-23 15:20:03[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-10-23 15:20:03[ INFO](Server.java:419) Started @6520ms
2019-10-23 15:20:03[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 15:20:03[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-10-23 15:20:03[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-10-23 15:20:03[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-10-23 15:20:03[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55629.
2019-10-23 15:20:03[ INFO](Logging.scala:54) Server created on TKK-YXKJ:55629
2019-10-23 15:20:03[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 55629, None)
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:55629 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 55629, None)
2019-10-23 15:20:03[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 55629, None)
2019-10-23 15:20:03[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 55629, None)
2019-10-23 15:20:03[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-10-23 15:20:05[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-10-23 15:20:05[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@297c9a9b{/SQL,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@20999517{/SQL/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@479ac2cb{/SQL/execution,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@220c9a63{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6c184d4d{/static/sql,null,AVAILABLE,@Spark}
2019-10-23 15:20:05[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-10-23 15:20:05[ INFO](Logging.scala:54) Code generated in 167.9288 ms
2019-10-23 15:20:06[ INFO](Logging.scala:54) Code generated in 5.5408 ms
2019-10-23 15:20:06[ INFO](Logging.scala:54) Starting job: json at TestJsonSource.java:29
2019-10-23 15:20:06[ INFO](Logging.scala:54) Got job 0 (json at TestJsonSource.java:29) with 1 output partitions
2019-10-23 15:20:06[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at TestJsonSource.java:29)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Parents of final stage: List()
2019-10-23 15:20:06[ INFO](Logging.scala:54) Missing parents: List()
2019-10-23 15:20:06[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at TestJsonSource.java:29), which has no missing parents
2019-10-23 15:20:06[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 5.4 KB, free 896.4 MB)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 896.4 MB)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:55629 (size: 3.4 KB, free: 896.4 MB)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Created broadcast 0 from broadcast at DAGScheduler.scala:1161
2019-10-23 15:20:06[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at TestJsonSource.java:29) (first 15 tasks are for partitions Vector(0))
2019-10-23 15:20:06[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-10-23 15:20:06[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8108 bytes)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1754 bytes result sent to driver
2019-10-23 15:20:06[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 50 ms on localhost (executor driver) (1/1)
2019-10-23 15:20:06[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-10-23 15:20:06[ INFO](Logging.scala:54) ResultStage 0 (json at TestJsonSource.java:29) finished in 0.790 s
2019-10-23 15:20:06[ INFO](Logging.scala:54) Job 0 finished: json at TestJsonSource.java:29, took 0.819966 s
2019-10-23 15:20:07[ INFO](Logging.scala:54) Code generated in 9.1595 ms
2019-10-23 15:20:07[ INFO](Logging.scala:54) Code generated in 12.4519 ms
2019-10-23 15:20:07[ INFO](Logging.scala:54) Starting job: show at TestJsonSource.java:30
2019-10-23 15:20:07[ INFO](Logging.scala:54) Got job 1 (show at TestJsonSource.java:30) with 1 output partitions
2019-10-23 15:20:07[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at TestJsonSource.java:30)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Parents of final stage: List()
2019-10-23 15:20:07[ INFO](Logging.scala:54) Missing parents: List()
2019-10-23 15:20:07[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[11] at show at TestJsonSource.java:30), which has no missing parents
2019-10-23 15:20:07[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 13.4 KB, free 896.4 MB)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.9 KB, free 896.4 MB)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:55629 (size: 6.9 KB, free: 896.4 MB)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-10-23 15:20:07[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at show at TestJsonSource.java:30) (first 15 tasks are for partitions Vector(0))
2019-10-23 15:20:07[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-10-23 15:20:07[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8108 bytes)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Code generated in 6.1291 ms
2019-10-23 15:20:07[ INFO](Logging.scala:54) Code generated in 8.4713 ms
2019-10-23 15:20:07[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1119 bytes result sent to driver
2019-10-23 15:20:07[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
2019-10-23 15:20:07[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-10-23 15:20:07[ INFO](Logging.scala:54) ResultStage 1 (show at TestJsonSource.java:30) finished in 0.050 s
2019-10-23 15:20:07[ INFO](Logging.scala:54) Job 1 finished: show at TestJsonSource.java:30, took 0.057512 s
2019-10-23 15:20:07[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-10-23 15:20:07[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-10-23 15:20:07[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-10-23 15:20:07[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-10-23 15:20:07[ INFO](Logging.scala:54) MemoryStore cleared
2019-10-23 15:20:07[ INFO](Logging.scala:54) BlockManager stopped
2019-10-23 15:20:07[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-10-23 15:20:07[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-10-23 15:20:07[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-10-23 15:20:07[ INFO](Logging.scala:54) Shutdown hook called
2019-10-23 15:20:07[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-aa0d8707-cff2-4a38-82d3-a11d64076e6f
2019-11-1 18:30:29[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:30:29[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:30:29[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:30:30[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:30:30[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:30:30[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:30:30[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:30:31[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65085.
2019-11-1 18:30:31[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:30:31[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:30:31[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:30:31[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:30:32[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-9ed3acac-6ac9-4489-ba78-d7353015e42b
2019-11-1 18:30:32[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:30:32[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:30:32[ INFO](Log.java:192) Logging initialized @4132ms
2019-11-1 18:30:32[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:30:32[ INFO](Server.java:419) Started @4190ms
2019-11-1 18:30:32[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:30:32[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:30:32[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:30:32[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:30:33[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65126.
2019-11-1 18:30:33[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65126
2019-11-1 18:30:33[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:30:33[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65126, None)
2019-11-1 18:30:33[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65126 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65126, None)
2019-11-1 18:30:33[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65126, None)
2019-11-1 18:30:33[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65126, None)
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-11-1 18:30:33[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2d7e1102{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@65327f5{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@72458efc{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@36bc415e{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@72ba28ee{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:30:33[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:30:35[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:30:35[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:30:35[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:30:35[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:30:35[ INFO](Logging.scala:54) Code generated in 240.9073 ms
2019-11-1 18:30:35[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65126 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:13
2019-11-1 18:30:36[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:30:36[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:13
2019-11-1 18:30:36[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:13) with 1 output partitions
2019-11-1 18:30:36[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:13)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:30:36[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:30:36[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13), which has no missing parents
2019-11-1 18:30:36[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65126 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:30:36[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:30:36[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:30:36[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8326 bytes)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student., range: 0-91, partition values: [empty row]
2019-11-1 18:30:36[ INFO](Logging.scala:54) Code generated in 9.9086 ms
2019-11-1 18:30:36[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1807 bytes result sent to driver
2019-11-1 18:30:36[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 134 ms on localhost (executor driver) (1/1)
2019-11-1 18:30:36[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:30:36[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:13) finished in 0.202 s
2019-11-1 18:30:36[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:13, took 0.243851 s
2019-11-1 18:30:36[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:30:36[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:30:36[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:30:36[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:30:36[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:30:36[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:30:36[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:30:36[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:30:36[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:30:36[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:30:36[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-5f542e53-cac0-4a62-a6a4-de2466b5affd
2019-11-1 18:30:51[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:30:51[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:30:51[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:30:51[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:30:51[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:30:51[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:30:51[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:30:53[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65176.
2019-11-1 18:30:53[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:30:53[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:30:53[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:30:53[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:30:54[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-c239da22-5a50-4ece-b42e-69d4ee2782a5
2019-11-1 18:30:54[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:30:54[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:30:54[ INFO](Log.java:192) Logging initialized @3684ms
2019-11-1 18:30:54[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:30:54[ INFO](Server.java:419) Started @3731ms
2019-11-1 18:30:54[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:30:54[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:30:54[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:30:54[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65218.
2019-11-1 18:30:54[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65218
2019-11-1 18:30:54[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:30:54[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65218, None)
2019-11-1 18:30:54[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65218 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65218, None)
2019-11-1 18:30:54[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65218, None)
2019-11-1 18:30:54[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65218, None)
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-11-1 18:30:54[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:30:54[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:30:55[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:30:56[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:30:56[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:30:56[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:30:56[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:30:56[ INFO](Logging.scala:54) Code generated in 212.6224 ms
2019-11-1 18:30:57[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65218 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:13
2019-11-1 18:30:57[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:30:57[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:13
2019-11-1 18:30:57[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:13) with 1 output partitions
2019-11-1 18:30:57[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:13)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:30:57[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:30:57[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13), which has no missing parents
2019-11-1 18:30:57[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65218 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:30:57[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:30:57[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:30:57[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-91, partition values: [empty row]
2019-11-1 18:30:57[ INFO](Logging.scala:54) Code generated in 11.7815 ms
2019-11-1 18:30:57[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1850 bytes result sent to driver
2019-11-1 18:30:57[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (executor driver) (1/1)
2019-11-1 18:30:57[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:30:57[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:13) finished in 0.190 s
2019-11-1 18:30:57[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:13, took 0.222285 s
2019-11-1 18:30:57[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:30:57[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:30:57[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:30:57[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:30:57[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:30:57[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:30:57[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:30:57[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:30:57[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:30:57[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:30:57[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-161d84c9-8268-4708-bdf0-a0e642c51556
2019-11-1 18:31:23[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:31:23[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:31:23[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:31:23[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:31:23[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:31:23[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:31:23[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:31:25[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65272.
2019-11-1 18:31:25[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:31:25[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:31:25[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:31:25[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:31:26[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-ab946078-e60d-424f-989f-391c651fa0a0
2019-11-1 18:31:26[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:31:26[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:31:26[ INFO](Log.java:192) Logging initialized @3684ms
2019-11-1 18:31:26[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:31:26[ INFO](Server.java:419) Started @3732ms
2019-11-1 18:31:26[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:31:26[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:31:26[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:31:26[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65313.
2019-11-1 18:31:26[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65313
2019-11-1 18:31:26[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:31:26[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65313, None)
2019-11-1 18:31:26[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65313 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65313, None)
2019-11-1 18:31:26[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65313, None)
2019-11-1 18:31:26[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65313, None)
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse').
2019-11-1 18:31:26[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse'.
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:31:27[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:31:28[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:31:28[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:31:28[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:31:28[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:31:28[ INFO](Logging.scala:54) Code generated in 215.413 ms
2019-11-1 18:31:28[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65313 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:13
2019-11-1 18:31:29[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:31:29[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:13
2019-11-1 18:31:29[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:13) with 1 output partitions
2019-11-1 18:31:29[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:13)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:31:29[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:31:29[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13), which has no missing parents
2019-11-1 18:31:29[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65313 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:31:29[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:31:29[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:31:29[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-91, partition values: [empty row]
2019-11-1 18:31:29[ INFO](Logging.scala:54) Code generated in 12.5678 ms
2019-11-1 18:31:29[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1807 bytes result sent to driver
2019-11-1 18:31:29[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (executor driver) (1/1)
2019-11-1 18:31:29[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:31:29[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:13) finished in 0.187 s
2019-11-1 18:31:29[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:13, took 0.221131 s
2019-11-1 18:31:29[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:31:29[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:31:29[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:31:29[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:31:29[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:31:29[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:31:29[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:31:29[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:31:29[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:31:29[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:31:29[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-7eff38b5-4009-408a-adbf-35a0f6245116
2019-11-1 18:34:37[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:34:37[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:34:37[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:34:37[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:34:37[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:34:37[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:34:37[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:34:39[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65433.
2019-11-1 18:34:39[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:34:39[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:34:39[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:34:39[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:34:40[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-7c76d481-653c-4a1f-9aa0-0960388790e6
2019-11-1 18:34:40[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:34:40[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:34:40[ INFO](Log.java:192) Logging initialized @3844ms
2019-11-1 18:34:40[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:34:40[ INFO](Server.java:419) Started @3892ms
2019-11-1 18:34:40[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:34:40[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:34:40[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:34:40[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:34:40[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65474.
2019-11-1 18:34:40[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65474
2019-11-1 18:34:40[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:34:40[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65474, None)
2019-11-1 18:34:40[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65474 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65474, None)
2019-11-1 18:34:40[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65474, None)
2019-11-1 18:34:40[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65474, None)
2019-11-1 18:34:40[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-1 18:34:41[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-1 18:34:41[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:34:41[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:34:42[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:34:42[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:34:42[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:34:42[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:34:43[ INFO](Logging.scala:54) Code generated in 210.8084 ms
2019-11-1 18:34:43[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65474 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:13
2019-11-1 18:34:43[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:34:43[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:13
2019-11-1 18:34:43[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:13) with 1 output partitions
2019-11-1 18:34:43[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:13)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:34:43[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:34:43[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13), which has no missing parents
2019-11-1 18:34:43[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65474 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:34:43[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:34:43[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:34:43[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:34:43[ INFO](Logging.scala:54) Code generated in 10.5235 ms
2019-11-1 18:34:43[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1889 bytes result sent to driver
2019-11-1 18:34:43[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 130 ms on localhost (executor driver) (1/1)
2019-11-1 18:34:43[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:34:43[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:13) finished in 0.190 s
2019-11-1 18:34:43[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:13, took 0.220825 s
2019-11-1 18:34:44[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:34:44[ INFO](Logging.scala:54) Post-Scan Filters: isnotnull(age#6L),(age#6L > 18)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Output Data Schema: struct<age: bigint, name: string>
2019-11-1 18:34:44[ INFO](Logging.scala:54) Pushed Filters: IsNotNull(age),GreaterThan(age,18)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Code generated in 12.2292 ms
2019-11-1 18:34:44[ INFO](Logging.scala:54) Code generated in 8.2391 ms
2019-11-1 18:34:44[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.7 KB, free 895.9 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:65474 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Created broadcast 2 from show at SqlParse.java:15
2019-11-1 18:34:44[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:34:44[ INFO](Logging.scala:54) Starting job: show at SqlParse.java:15
2019-11-1 18:34:44[ INFO](Logging.scala:54) Got job 1 (show at SqlParse.java:15) with 1 output partitions
2019-11-1 18:34:44[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SqlParse.java:15)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:34:44[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:34:44[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:15), which has no missing parents
2019-11-1 18:34:44[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 895.9 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 895.9 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:65474 (size: 5.8 KB, free: 896.3 MB)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:34:44[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:15) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:34:44[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-1 18:34:44[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:34:44[ INFO](Logging.scala:54) Code generated in 6.0167 ms
2019-11-1 18:34:44[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1227 bytes result sent to driver
2019-11-1 18:34:44[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 31 ms on localhost (executor driver) (1/1)
2019-11-1 18:34:44[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-1 18:34:44[ INFO](Logging.scala:54) ResultStage 1 (show at SqlParse.java:15) finished in 0.040 s
2019-11-1 18:34:44[ INFO](Logging.scala:54) Job 1 finished: show at SqlParse.java:15, took 0.042188 s
2019-11-1 18:34:44[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:34:44[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:34:44[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:34:44[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:34:44[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:34:44[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:34:44[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:34:44[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:34:44[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:34:44[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:34:44[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-7b653464-3cc9-49d0-adc3-a3a7e27fadb6
2019-11-1 18:35:11[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:35:11[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:35:11[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:35:11[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:35:11[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:35:11[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:35:11[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:35:13[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65528.
2019-11-1 18:35:13[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:35:13[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:35:13[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:35:13[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:35:14[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-8cf9c248-d6be-4e15-96b1-d0dd79f6a292
2019-11-1 18:35:14[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:35:14[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:35:14[ INFO](Log.java:192) Logging initialized @3744ms
2019-11-1 18:35:14[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:35:14[ INFO](Server.java:419) Started @3791ms
2019-11-1 18:35:14[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:35:14[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:35:14[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:35:14[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49187.
2019-11-1 18:35:14[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49187
2019-11-1 18:35:14[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:35:14[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49187, None)
2019-11-1 18:35:14[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49187 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49187, None)
2019-11-1 18:35:14[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49187, None)
2019-11-1 18:35:14[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49187, None)
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-1 18:35:14[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:14[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:35:15[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:35:16[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:35:16[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:35:16[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:35:16[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:35:16[ INFO](Logging.scala:54) Code generated in 213.6638 ms
2019-11-1 18:35:16[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49187 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:13
2019-11-1 18:35:17[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:35:17[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:13
2019-11-1 18:35:17[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:13) with 1 output partitions
2019-11-1 18:35:17[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:13)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:35:17[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:35:17[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13), which has no missing parents
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49187 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:35:17[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:13) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:35:17[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:35:17[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:35:17[ INFO](Logging.scala:54) Code generated in 11.9264 ms
2019-11-1 18:35:17[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1932 bytes result sent to driver
2019-11-1 18:35:17[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 132 ms on localhost (executor driver) (1/1)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:35:17[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:13) finished in 0.191 s
2019-11-1 18:35:17[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:13, took 0.222499 s
2019-11-1 18:35:17[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:35:17[ INFO](Logging.scala:54) Post-Scan Filters: isnotnull(age#6L),(age#6L > 18)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Output Data Schema: struct<age: bigint, name: string>
2019-11-1 18:35:17[ INFO](Logging.scala:54) Pushed Filters: IsNotNull(age),GreaterThan(age,18)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Code generated in 12.0856 ms
2019-11-1 18:35:17[ INFO](Logging.scala:54) Code generated in 9.5973 ms
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.7 KB, free 895.9 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49187 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Created broadcast 2 from show at SqlParse.java:15
2019-11-1 18:35:17[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:35:17[ INFO](Logging.scala:54) Starting job: show at SqlParse.java:15
2019-11-1 18:35:17[ INFO](Logging.scala:54) Got job 1 (show at SqlParse.java:15) with 1 output partitions
2019-11-1 18:35:17[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SqlParse.java:15)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:35:17[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:35:17[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:15), which has no missing parents
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 895.9 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 895.9 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49187 (size: 5.8 KB, free: 896.3 MB)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:35:17[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:15) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:35:17[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-1 18:35:17[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-1 18:35:17[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:35:17[ INFO](Logging.scala:54) Code generated in 7.406 ms
2019-11-1 18:35:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1279 bytes result sent to driver
2019-11-1 18:35:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (executor driver) (1/1)
2019-11-1 18:35:18[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-1 18:35:18[ INFO](Logging.scala:54) ResultStage 1 (show at SqlParse.java:15) finished in 0.049 s
2019-11-1 18:35:18[ INFO](Logging.scala:54) Job 1 finished: show at SqlParse.java:15, took 0.052078 s
2019-11-1 18:35:18[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:35:18[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:35:18[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:35:18[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:35:18[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:35:18[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:35:18[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:35:18[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:35:18[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:35:18[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:35:18[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-6bed0432-da15-4451-a120-b23be0dffe93
2019-11-1 18:35:45[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:35:45[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:35:45[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:35:45[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:35:45[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:35:45[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:35:45[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:35:47[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49240.
2019-11-1 18:35:47[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:35:47[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:35:47[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:35:47[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:35:48[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-50db58c0-1615-48c9-82dc-b065fc11479b
2019-11-1 18:35:48[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:35:48[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:35:48[ INFO](Log.java:192) Logging initialized @3867ms
2019-11-1 18:35:48[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:35:48[ INFO](Server.java:419) Started @3914ms
2019-11-1 18:35:48[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:35:48[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:35:48[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:35:48[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49281.
2019-11-1 18:35:48[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49281
2019-11-1 18:35:48[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:35:48[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49281, None)
2019-11-1 18:35:48[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49281 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49281, None)
2019-11-1 18:35:48[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49281, None)
2019-11-1 18:35:48[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49281, None)
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-1 18:35:48[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:35:48[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:35:49[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:35:50[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:35:50[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:35:50[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:35:50[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:35:51[ INFO](Logging.scala:54) Code generated in 234.0083 ms
2019-11-1 18:35:51[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49281 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:17
2019-11-1 18:35:51[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:35:51[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:17
2019-11-1 18:35:51[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:17) with 1 output partitions
2019-11-1 18:35:51[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:17)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:35:51[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:35:51[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17), which has no missing parents
2019-11-1 18:35:51[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49281 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:35:51[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:35:51[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:35:51[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:35:51[ INFO](Logging.scala:54) Code generated in 13.1813 ms
2019-11-1 18:35:51[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1975 bytes result sent to driver
2019-11-1 18:35:51[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 152 ms on localhost (executor driver) (1/1)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:35:51[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:17) finished in 0.219 s
2019-11-1 18:35:51[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:17, took 0.253102 s
2019-11-1 18:35:51[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:35:51[ INFO](Logging.scala:54) Post-Scan Filters: isnotnull(age#6L),(age#6L > 18)
2019-11-1 18:35:51[ INFO](Logging.scala:54) Output Data Schema: struct<age: bigint, name: string>
2019-11-1 18:35:51[ INFO](Logging.scala:54) Pushed Filters: IsNotNull(age),GreaterThan(age,18)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Code generated in 13.0488 ms
2019-11-1 18:35:52[ INFO](Logging.scala:54) Code generated in 9.3425 ms
2019-11-1 18:35:52[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.7 KB, free 895.9 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49281 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Created broadcast 2 from show at SqlParse.java:19
2019-11-1 18:35:52[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:35:52[ INFO](Logging.scala:54) Starting job: show at SqlParse.java:19
2019-11-1 18:35:52[ INFO](Logging.scala:54) Got job 1 (show at SqlParse.java:19) with 1 output partitions
2019-11-1 18:35:52[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SqlParse.java:19)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:35:52[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:35:52[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19), which has no missing parents
2019-11-1 18:35:52[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 895.9 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 895.9 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49281 (size: 5.8 KB, free: 896.3 MB)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:35:52[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:35:52[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-1 18:35:52[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:35:52[ INFO](Logging.scala:54) Code generated in 6.9505 ms
2019-11-1 18:35:52[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1236 bytes result sent to driver
2019-11-1 18:35:52[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 33 ms on localhost (executor driver) (1/1)
2019-11-1 18:35:52[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-1 18:35:52[ INFO](Logging.scala:54) ResultStage 1 (show at SqlParse.java:19) finished in 0.046 s
2019-11-1 18:35:52[ INFO](Logging.scala:54) Job 1 finished: show at SqlParse.java:19, took 0.048183 s
2019-11-1 18:35:52[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:35:52[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:35:52[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:35:52[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:35:52[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:35:52[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:35:52[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:35:52[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:35:52[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:35:52[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:35:52[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-c6fb3291-5c89-40de-9e2a-39f556ff7fc5
2019-11-1 18:36:08[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-1 18:36:09[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-1 18:36:09[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-1 18:36:09[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-1 18:36:09[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-1 18:36:09[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-1 18:36:09[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-1 18:36:11[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49331.
2019-11-1 18:36:11[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-1 18:36:11[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-1 18:36:11[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-1 18:36:11[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-1 18:36:11[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-db64ad7b-e6d2-4c24-af86-549eb50abe5e
2019-11-1 18:36:11[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-1 18:36:11[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-1 18:36:11[ INFO](Log.java:192) Logging initialized @3792ms
2019-11-1 18:36:11[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-1 18:36:11[ INFO](Server.java:419) Started @3840ms
2019-11-1 18:36:11[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:36:11[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-1 18:36:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-1 18:36:12[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-1 18:36:12[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49372.
2019-11-1 18:36:12[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49372
2019-11-1 18:36:12[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-1 18:36:12[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49372, None)
2019-11-1 18:36:12[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49372 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49372, None)
2019-11-1 18:36:12[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49372, None)
2019-11-1 18:36:12[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49372, None)
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-1 18:36:12[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@466d49f0{/SQL,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@710d7aff{/SQL/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@301d8120{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6d367020{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6a714237{/static/sql,null,AVAILABLE,@Spark}
2019-11-1 18:36:12[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-1 18:36:14[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:36:14[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-1 18:36:14[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-1 18:36:14[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-1 18:36:14[ INFO](Logging.scala:54) Code generated in 232.1849 ms
2019-11-1 18:36:14[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-1 18:36:14[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-1 18:36:14[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49372 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:36:14[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:17
2019-11-1 18:36:14[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:36:15[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:17
2019-11-1 18:36:15[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:17) with 1 output partitions
2019-11-1 18:36:15[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:17)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:36:15[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:36:15[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17), which has no missing parents
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49372 (size: 5.4 KB, free: 896.4 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:36:15[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:36:15[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-1 18:36:15[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:36:15[ INFO](Logging.scala:54) Code generated in 12.5456 ms
2019-11-1 18:36:15[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1975 bytes result sent to driver
2019-11-1 18:36:15[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 149 ms on localhost (executor driver) (1/1)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-1 18:36:15[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:17) finished in 0.218 s
2019-11-1 18:36:15[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:17, took 0.251163 s
2019-11-1 18:36:15[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-1 18:36:15[ INFO](Logging.scala:54) Post-Scan Filters: isnotnull(age#6L),(age#6L > 18)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Output Data Schema: struct<age: bigint, name: string>
2019-11-1 18:36:15[ INFO](Logging.scala:54) Pushed Filters: IsNotNull(age),GreaterThan(age,18)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Code generated in 14.8582 ms
2019-11-1 18:36:15[ INFO](Logging.scala:54) Code generated in 10.356 ms
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.7 KB, free 895.9 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49372 (size: 20.6 KB, free: 896.4 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Created broadcast 2 from show at SqlParse.java:19
2019-11-1 18:36:15[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-1 18:36:15[ INFO](Logging.scala:54) Starting job: show at SqlParse.java:19
2019-11-1 18:36:15[ INFO](Logging.scala:54) Got job 1 (show at SqlParse.java:19) with 1 output partitions
2019-11-1 18:36:15[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SqlParse.java:19)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-1 18:36:15[ INFO](Logging.scala:54) Missing parents: List()
2019-11-1 18:36:15[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19), which has no missing parents
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 895.9 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 895.9 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49372 (size: 5.8 KB, free: 896.3 MB)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-1 18:36:15[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19) (first 15 tasks are for partitions Vector(0))
2019-11-1 18:36:15[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-1 18:36:15[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-1 18:36:15[ INFO](Logging.scala:54) Code generated in 7.8566 ms
2019-11-1 18:36:15[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1279 bytes result sent to driver
2019-11-1 18:36:15[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 40 ms on localhost (executor driver) (1/1)
2019-11-1 18:36:15[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-1 18:36:15[ INFO](Logging.scala:54) ResultStage 1 (show at SqlParse.java:19) finished in 0.053 s
2019-11-1 18:36:15[ INFO](Logging.scala:54) Job 1 finished: show at SqlParse.java:19, took 0.055403 s
2019-11-1 18:36:15[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-1 18:36:15[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-1 18:36:15[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-1 18:36:15[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-1 18:36:15[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-1 18:36:15[ INFO](Logging.scala:54) BlockManager stopped
2019-11-1 18:36:15[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-1 18:36:15[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-1 18:36:15[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-1 18:36:15[ INFO](Logging.scala:54) Shutdown hook called
2019-11-1 18:36:15[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-56c2a16c-0fc3-4132-a43f-cb04d1d606ba
2019-11-21 16:25:35[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:25:35[ INFO](Logging.scala:54) Submitted application: TestSort
2019-11-21 16:25:35[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:25:35[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:25:35[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:25:35[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:25:35[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:25:37[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 64978.
2019-11-21 16:25:37[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:25:37[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:25:37[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:25:37[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:25:38[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-856f44f4-2163-4f34-a57b-cd1521de4f1e
2019-11-21 16:25:38[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:25:38[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:25:38[ INFO](Log.java:192) Logging initialized @3577ms
2019-11-21 16:25:38[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:25:38[ INFO](Server.java:419) Started @3637ms
2019-11-21 16:25:38[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:25:38[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:25:38[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:25:38[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65019.
2019-11-21 16:25:38[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65019
2019-11-21 16:25:38[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:25:38[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65019, None)
2019-11-21 16:25:38[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65019 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65019, None)
2019-11-21 16:25:38[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65019, None)
2019-11-21 16:25:38[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65019, None)
2019-11-21 16:25:38[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:25:38[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:25:38[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65019 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:25:39[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65019 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:25:39[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:25:39[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:25:39[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:25:39[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:25:39[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:25:39[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:25:39[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:25:39[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:25:39[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:25:39[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:25:39[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:25:39[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-8aeabd25-3ba5-477b-9eff-aa50b5bf2778
2019-11-21 16:27:04[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:27:04[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:27:05[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:27:05[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:27:05[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:27:05[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:27:05[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:27:06[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65086.
2019-11-21 16:27:06[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:27:06[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:27:06[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:27:06[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:27:07[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-a5168613-893b-4c7b-8928-1e390fd5efd2
2019-11-21 16:27:07[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:27:07[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:27:07[ INFO](Log.java:192) Logging initialized @3105ms
2019-11-21 16:27:07[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:27:07[ INFO](Server.java:419) Started @3153ms
2019-11-21 16:27:07[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:27:07[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:27:07[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:27:07[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65127.
2019-11-21 16:27:07[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65127
2019-11-21 16:27:07[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:27:07[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65127, None)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65127 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65127, None)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65127, None)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65127, None)
2019-11-21 16:27:07[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:27:07[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:27:07[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65127 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:27:07[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65127 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:27:07[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:27:07[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:27:07[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:27:07[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:73
2019-11-21 16:27:08[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:47)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:52)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:73) with 4 output partitions
2019-11-21 16:27:08[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:73)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47), which has no missing parents
2019-11-21 16:27:08[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:65127 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:27:08[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:27:08[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:27:08[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:27:08[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:17+18
2019-11-21 16:27:08[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:64+64
2019-11-21 16:27:08[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+17
2019-11-21 16:27:08[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+64
2019-11-21 16:27:08[ERROR](Logging.scala:91) Exception in task 2.0 in stage 0.0 (TID 2)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$3fbb82f0$1(SparkLeftOutJoin.java:36)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:27:08[ERROR](Logging.scala:91) Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:27:08[ERROR](Logging.scala:91) Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:27:08[ERROR](Logging.scala:91) Exception in task 3.0 in stage 0.0 (TID 3)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$3fbb82f0$1(SparkLeftOutJoin.java:36)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:27:08[ WARN](Logging.scala:66) Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$3fbb82f0$1(SparkLeftOutJoin.java:36)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2019-11-21 16:27:08[ERROR](Logging.scala:70) Task 2 in stage 0.0 failed 1 times; aborting job
2019-11-21 16:27:08[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:27:08[ INFO](Logging.scala:54) Lost task 3.0 in stage 0.0 (TID 3) on localhost, executor driver: java.lang.ArrayIndexOutOfBoundsException (1) [duplicate 1]
2019-11-21 16:27:08[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:27:08[ INFO](Logging.scala:54) Lost task 0.0 in stage 0.0 (TID 0) on localhost, executor driver: java.lang.ArrayIndexOutOfBoundsException (1) [duplicate 2]
2019-11-21 16:27:08[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:27:08[ INFO](Logging.scala:54) Lost task 1.0 in stage 0.0 (TID 1) on localhost, executor driver: java.lang.ArrayIndexOutOfBoundsException (1) [duplicate 3]
2019-11-21 16:27:08[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:27:08[ INFO](Logging.scala:54) Cancelling stage 0
2019-11-21 16:27:08[ INFO](Logging.scala:54) Killing all running tasks in stage 0: Stage cancelled
2019-11-21 16:27:08[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:47) failed in 0.190 s due to Job aborted due to stage failure: Task 2 in stage 0.0 failed 1 times, most recent failure: Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$3fbb82f0$1(SparkLeftOutJoin.java:36)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2019-11-21 16:27:08[ INFO](Logging.scala:54) Job 0 failed: collect at SparkLeftOutJoin.java:73, took 0.242994 s
2019-11-21 16:27:08[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:27:08[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:27:08[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:27:08[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:27:08[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:27:08[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:27:08[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:27:08[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:27:08[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:27:08[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:27:08[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-80e17ec8-9fac-4cde-9dbf-4f8c1f71ede3
2019-11-21 16:31:23[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:31:23[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:31:23[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:31:23[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:31:23[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:31:23[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:31:23[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:31:25[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65256.
2019-11-21 16:31:25[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:31:25[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:31:25[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:31:25[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:31:26[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-a240e2ab-a3cf-4882-a025-7432cf353ddd
2019-11-21 16:31:26[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:31:26[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:31:26[ INFO](Log.java:192) Logging initialized @3169ms
2019-11-21 16:31:26[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:31:26[ INFO](Server.java:419) Started @3216ms
2019-11-21 16:31:26[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:31:26[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:31:26[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:31:26[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65299.
2019-11-21 16:31:26[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65299
2019-11-21 16:31:26[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:31:26[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65299, None)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65299 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65299, None)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65299, None)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65299, None)
2019-11-21 16:31:26[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:31:26[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:31:26[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65299 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:31:26[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65299 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:31:26[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:31:26[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:31:26[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:31:27[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:73
2019-11-21 16:31:27[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:47)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:52)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:73) with 4 output partitions
2019-11-21 16:31:27[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:73)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47), which has no missing parents
2019-11-21 16:31:27[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:65299 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:31:27[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:31:27[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:31:27[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:64+64
2019-11-21 16:31:27[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:17+18
2019-11-21 16:31:27[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+64
2019-11-21 16:31:27[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+17
2019-11-21 16:31:27[ERROR](Logging.scala:91) Exception in task 1.0 in stage 0.0 (TID 1)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:31:27[ERROR](Logging.scala:91) Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 894 bytes result sent to driver
2019-11-21 16:31:27[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 894 bytes result sent to driver
2019-11-21 16:31:27[ WARN](Logging.scala:66) Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2019-11-21 16:31:27[ERROR](Logging.scala:70) Task 1 in stage 0.0 failed 1 times; aborting job
2019-11-21 16:31:27[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:31:27[ INFO](Logging.scala:54) Lost task 0.0 in stage 0.0 (TID 0) on localhost, executor driver: java.lang.ArrayIndexOutOfBoundsException (1) [duplicate 1]
2019-11-21 16:31:27[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:31:27[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 116 ms on localhost (executor driver) (1/4)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:31:27[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 116 ms on localhost (executor driver) (2/4)
2019-11-21 16:31:27[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:31:27[ INFO](Logging.scala:54) Cancelling stage 0
2019-11-21 16:31:27[ INFO](Logging.scala:54) Killing all running tasks in stage 0: Stage cancelled
2019-11-21 16:31:27[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:47) failed in 0.166 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 1 times, most recent failure: Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): java.lang.ArrayIndexOutOfBoundsException: 1
	at sparkkstreaming.algorithm.union.SparkLeftOutJoin.lambda$useSparkRDD$8eaf1ba3$1(SparkLeftOutJoin.java:43)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at org.apache.spark.api.java.JavaPairRDD$$anonfun$pairFunToScalaFun$1.apply(JavaPairRDD.scala:1043)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409)
	at org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:149)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2019-11-21 16:31:27[ INFO](Logging.scala:54) Job 0 failed: collect at SparkLeftOutJoin.java:73, took 0.212042 s
2019-11-21 16:31:27[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:31:27[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:31:27[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:31:27[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:31:27[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:31:27[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:31:27[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:31:27[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:31:27[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:31:27[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:31:27[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-02c986ae-e87d-4058-a986-1c350138acac
2019-11-21 16:32:36[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:32:37[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:32:37[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:32:37[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:32:37[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:32:37[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:32:37[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:32:38[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 65362.
2019-11-21 16:32:38[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:32:38[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:32:38[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:32:38[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:32:39[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-94d772c6-b1d9-49a8-9d69-6fecf1394831
2019-11-21 16:32:39[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:32:39[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:32:39[ INFO](Log.java:192) Logging initialized @3163ms
2019-11-21 16:32:39[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:32:39[ INFO](Server.java:419) Started @3210ms
2019-11-21 16:32:39[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:32:39[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:32:39[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:32:39[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65403.
2019-11-21 16:32:39[ INFO](Logging.scala:54) Server created on TKK-YXKJ:65403
2019-11-21 16:32:39[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:32:39[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 65403, None)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:65403 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 65403, None)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 65403, None)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 65403, None)
2019-11-21 16:32:39[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:32:39[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:32:39[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:65403 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:32:39[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:65403 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:32:39[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:32:40[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:32:40[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:73
2019-11-21 16:32:40[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:47)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:52)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:73) with 4 output partitions
2019-11-21 16:32:40[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:73)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47), which has no missing parents
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:65403 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:32:40[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:64+64
2019-11-21 16:32:40[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:17+18
2019-11-21 16:32:40[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+64
2019-11-21 16:32:40[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+17
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 937 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 980 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 980 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1). 937 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1) in 118 ms on localhost (executor driver) (1/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 128 ms on localhost (executor driver) (2/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 118 ms on localhost (executor driver) (3/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 118 ms on localhost (executor driver) (4/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:32:40[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:47) finished in 0.178 s
2019-11-21 16:32:40[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:32:40[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:32:40[ INFO](Logging.scala:54) waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-11-21 16:32:40[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52), which has no missing parents
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 8.5 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:65403 (size: 4.4 KB, free: 896.4 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:32:40[ INFO](Logging.scala:54) Adding task set 1.0 with 4 tasks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7651 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7651 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7651 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7651 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 5)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 3.0 in stage 1.0 (TID 7)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 2.0 in stage 1.0 (TID 6)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6). 1109 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6) in 60 ms on localhost (executor driver) (1/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7). 1281 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7) in 70 ms on localhost (executor driver) (2/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4). 1324 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4) in 80 ms on localhost (executor driver) (3/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5). 1324 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5) in 80 ms on localhost (executor driver) (4/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:32:40[ INFO](Logging.scala:54) ShuffleMapStage 1 (flatMapToPair at SparkLeftOutJoin.java:52) finished in 0.090 s
2019-11-21 16:32:40[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:32:40[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:32:40[ INFO](Logging.scala:54) waiting: Set(ResultStage 2)
2019-11-21 16:32:40[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72), which has no missing parents
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 895.9 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:65403 (size: 4.6 KB, free: 896.3 MB)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:32:40[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:32:40[ INFO](Logging.scala:54) Adding task set 2.0 with 4 tasks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 1.0 in stage 2.0 (TID 9)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 3.0 in stage 2.0 (TID 11)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 8)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Running task 2.0 in stage 2.0 (TID 10)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:32:40[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9). 3616 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11). 3561 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8). 3616 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10). 3561 bytes result sent to driver
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:32:40[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 16:32:40[ INFO](Logging.scala:54) ResultStage 2 (collect at SparkLeftOutJoin.java:73) finished in 0.020 s
2019-11-21 16:32:40[ INFO](Logging.scala:54) Job 0 finished: collect at SparkLeftOutJoin.java:73, took 0.339018 s
2019-11-21 16:32:40[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:32:40[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:32:40[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:32:40[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:32:40[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:32:40[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:32:40[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:32:40[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:32:40[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:32:40[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:32:40[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-7be62e7e-ca0a-4f86-bb7d-bec19f269a86
2019-11-21 16:38:27[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:38:27[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:38:27[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:38:27[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:38:27[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:38:27[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:38:27[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:38:29[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49190.
2019-11-21 16:38:29[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:38:29[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:38:29[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:38:29[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:38:30[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-23db4b20-1934-4428-b22c-c5bb4c52e827
2019-11-21 16:38:30[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:38:30[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:38:30[ INFO](Log.java:192) Logging initialized @3134ms
2019-11-21 16:38:30[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:38:30[ INFO](Server.java:419) Started @3182ms
2019-11-21 16:38:30[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:38:30[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:38:30[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:38:30[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49231.
2019-11-21 16:38:30[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49231
2019-11-21 16:38:30[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:38:30[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49231, None)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49231 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49231, None)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49231, None)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49231, None)
2019-11-21 16:38:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:38:30[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:38:30[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49231 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:38:30[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49231 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:38:30[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:38:30[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:38:30[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:73
2019-11-21 16:38:31[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:47)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:52)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:73) with 4 output partitions
2019-11-21 16:38:31[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:73)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47), which has no missing parents
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49231 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:38:31[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+80
2019-11-21 16:38:31[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:80+80
2019-11-21 16:38:31[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:27+28
2019-11-21 16:38:31[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+27
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 937 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 937 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 937 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1). 937 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 110 ms on localhost (executor driver) (1/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1) in 110 ms on localhost (executor driver) (2/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 120 ms on localhost (executor driver) (3/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 110 ms on localhost (executor driver) (4/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:38:31[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:47) finished in 0.160 s
2019-11-21 16:38:31[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:38:31[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:38:31[ INFO](Logging.scala:54) waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-11-21 16:38:31[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52), which has no missing parents
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 8.5 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49231 (size: 4.4 KB, free: 896.4 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:38:31[ INFO](Logging.scala:54) Adding task set 1.0 with 4 tasks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7651 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7651 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7651 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7651 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 2.0 in stage 1.0 (TID 6)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 3.0 in stage 1.0 (TID 7)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 5)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6). 1109 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6) in 60 ms on localhost (executor driver) (1/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7). 1238 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7) in 70 ms on localhost (executor driver) (2/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4). 1238 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4) in 70 ms on localhost (executor driver) (3/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5). 1238 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5) in 80 ms on localhost (executor driver) (4/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:38:31[ INFO](Logging.scala:54) ShuffleMapStage 1 (flatMapToPair at SparkLeftOutJoin.java:52) finished in 0.090 s
2019-11-21 16:38:31[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:38:31[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:38:31[ INFO](Logging.scala:54) waiting: Set(ResultStage 2)
2019-11-21 16:38:31[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72), which has no missing parents
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 895.9 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:49231 (size: 4.6 KB, free: 896.3 MB)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:38:31[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:38:31[ INFO](Logging.scala:54) Adding task set 2.0 with 4 tasks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 1.0 in stage 2.0 (TID 9)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 3.0 in stage 2.0 (TID 11)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 2.0 in stage 2.0 (TID 10)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 8)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11). 3632 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10). 3569 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8). 3569 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9). 3628 bytes result sent to driver
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:38:31[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 16:38:31[ INFO](Logging.scala:54) ResultStage 2 (collect at SparkLeftOutJoin.java:73) finished in 0.020 s
2019-11-21 16:38:31[ INFO](Logging.scala:54) Job 0 finished: collect at SparkLeftOutJoin.java:73, took 0.329402 s
2019-11-21 16:38:31[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:38:31[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:38:31[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:38:31[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:38:31[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:38:31[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:38:31[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:38:31[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:38:31[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:38:31[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:38:31[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-cf71812f-6057-47a8-b5a2-ee985a1b5774
2019-11-21 16:39:08[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:39:08[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:39:08[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:39:08[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:39:08[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:39:08[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:39:08[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:39:09[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49282.
2019-11-21 16:39:09[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:39:10[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:39:10[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:39:10[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:39:10[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-ff9ad8eb-2009-48f9-b41c-69a08f39c077
2019-11-21 16:39:10[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:39:10[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:39:10[ INFO](Log.java:192) Logging initialized @3144ms
2019-11-21 16:39:10[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:39:10[ INFO](Server.java:419) Started @3192ms
2019-11-21 16:39:10[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:39:10[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:39:10[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:39:10[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:39:10[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49324.
2019-11-21 16:39:10[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49324
2019-11-21 16:39:10[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:39:10[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49324, None)
2019-11-21 16:39:10[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49324 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49324, None)
2019-11-21 16:39:10[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49324, None)
2019-11-21 16:39:10[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49324, None)
2019-11-21 16:39:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:39:11[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49324 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:33
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49324 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:40
2019-11-21 16:39:11[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:39:11[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:73
2019-11-21 16:39:11[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:47)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:52)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:73) with 4 output partitions
2019-11-21 16:39:11[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:73)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47), which has no missing parents
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49324 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:47) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:39:11[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:80+80
2019-11-21 16:39:11[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:27+28
2019-11-21 16:39:11[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+27
2019-11-21 16:39:11[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+80
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 894 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1). 894 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 894 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 894 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 116 ms on localhost (executor driver) (1/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 126 ms on localhost (executor driver) (2/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 136 ms on localhost (executor driver) (3/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1) in 126 ms on localhost (executor driver) (4/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:39:11[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:47) finished in 0.176 s
2019-11-21 16:39:11[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:39:11[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:39:11[ INFO](Logging.scala:54) waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-11-21 16:39:11[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52), which has no missing parents
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 8.5 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49324 (size: 4.4 KB, free: 896.4 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:52) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:39:11[ INFO](Logging.scala:54) Adding task set 1.0 with 4 tasks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7651 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7651 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7651 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7651 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 2.0 in stage 1.0 (TID 6)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 3.0 in stage 1.0 (TID 7)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 5)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6). 1109 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6) in 50 ms on localhost (executor driver) (1/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7). 1238 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7) in 60 ms on localhost (executor driver) (2/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4). 1238 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4) in 70 ms on localhost (executor driver) (3/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5). 1238 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5) in 70 ms on localhost (executor driver) (4/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:39:11[ INFO](Logging.scala:54) ShuffleMapStage 1 (flatMapToPair at SparkLeftOutJoin.java:52) finished in 0.080 s
2019-11-21 16:39:11[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:39:11[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:39:11[ INFO](Logging.scala:54) waiting: Set(ResultStage 2)
2019-11-21 16:39:11[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72), which has no missing parents
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 895.9 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:49324 (size: 4.6 KB, free: 896.3 MB)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:39:11[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:39:11[ INFO](Logging.scala:54) Adding task set 2.0 with 4 tasks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 1.0 in stage 2.0 (TID 9)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 2.0 in stage 2.0 (TID 10)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 8)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Running task 3.0 in stage 2.0 (TID 11)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9). 3671 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10). 3612 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8). 3612 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11). 3675 bytes result sent to driver
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:39:11[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 16:39:11[ INFO](Logging.scala:54) ResultStage 2 (collect at SparkLeftOutJoin.java:73) finished in 0.030 s
2019-11-21 16:39:11[ INFO](Logging.scala:54) Job 0 finished: collect at SparkLeftOutJoin.java:73, took 0.333624 s
2019-11-21 16:39:11[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:39:11[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:39:11[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:39:11[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:39:12[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:39:12[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:39:12[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:39:12[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:39:12[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:39:12[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:39:12[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-56eec7bc-4bd9-4ddb-867c-b4e694095b4c
2019-11-21 16:46:14[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:46:15[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:46:15[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:46:15[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:46:15[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:46:15[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:46:15[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:46:16[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49513.
2019-11-21 16:46:16[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:46:16[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:46:16[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:46:16[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:46:17[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-64ee22fd-e274-46f6-ac43-14d843652f50
2019-11-21 16:46:17[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:46:17[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:46:17[ INFO](Log.java:192) Logging initialized @3294ms
2019-11-21 16:46:17[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:46:17[ INFO](Server.java:419) Started @3342ms
2019-11-21 16:46:17[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:46:17[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:46:17[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:46:17[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49554.
2019-11-21 16:46:17[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49554
2019-11-21 16:46:17[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:46:17[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49554, None)
2019-11-21 16:46:17[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49554 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49554, None)
2019-11-21 16:46:17[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49554, None)
2019-11-21 16:46:17[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49554, None)
2019-11-21 16:46:17[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:46:17[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49554 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:36
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49554 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:43
2019-11-21 16:46:18[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:46:18[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:76
2019-11-21 16:46:18[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:50)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:55)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:76) with 4 output partitions
2019-11-21 16:46:18[ INFO](Logging.scala:54) Final stage: ResultStage 2 (collect at SparkLeftOutJoin.java:76)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 1)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 1)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:50), which has no missing parents
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49554 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:46:18[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+27
2019-11-21 16:46:18[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:80+80
2019-11-21 16:46:18[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:27+28
2019-11-21 16:46:18[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+80
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 937 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 937 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1). 937 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 937 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 144 ms on localhost (executor driver) (1/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 154 ms on localhost (executor driver) (2/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1) in 144 ms on localhost (executor driver) (3/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 144 ms on localhost (executor driver) (4/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:46:18[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:50) finished in 0.204 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:46:18[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:46:18[ INFO](Logging.scala:54) waiting: Set(ShuffleMapStage 1, ResultStage 2)
2019-11-21 16:46:18[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:55), which has no missing parents
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 8.5 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49554 (size: 4.4 KB, free: 896.4 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:55) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:46:18[ INFO](Logging.scala:54) Adding task set 1.0 with 4 tasks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7651 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7651 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7651 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7651 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 3.0 in stage 1.0 (TID 7)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 5)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 2.0 in stage 1.0 (TID 6)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6). 1109 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6) in 50 ms on localhost (executor driver) (1/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7). 1238 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7) in 50 ms on localhost (executor driver) (2/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5). 1238 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5) in 60 ms on localhost (executor driver) (3/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4). 1238 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4) in 60 ms on localhost (executor driver) (4/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:46:18[ INFO](Logging.scala:54) ShuffleMapStage 1 (flatMapToPair at SparkLeftOutJoin.java:55) finished in 0.070 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:46:18[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:46:18[ INFO](Logging.scala:54) waiting: Set(ResultStage 2)
2019-11-21 16:46:18[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:75), which has no missing parents
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 8.9 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:49554 (size: 4.6 KB, free: 896.3 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:75) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:46:18[ INFO](Logging.scala:54) Adding task set 2.0 with 4 tasks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 8, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 1.0 in stage 2.0 (TID 9, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 2.0 in stage 2.0 (TID 10, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 3.0 in stage 2.0 (TID 11, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 1.0 in stage 2.0 (TID 9)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 2.0 in stage 2.0 (TID 10)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 3.0 in stage 2.0 (TID 11)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 8)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10). 3612 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8). 3612 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11). 3675 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9). 3628 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 2.0 (TID 9) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 2.0 (TID 10) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 8) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 2.0 (TID 11) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 16:46:18[ INFO](Logging.scala:54) ResultStage 2 (collect at SparkLeftOutJoin.java:76) finished in 0.030 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) Job 0 finished: collect at SparkLeftOutJoin.java:76, took 0.360614 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:89
2019-11-21 16:46:18[ INFO](Logging.scala:54) Got job 1 (collect at SparkLeftOutJoin.java:89) with 4 output partitions
2019-11-21 16:46:18[ INFO](Logging.scala:54) Final stage: ResultStage 5 (collect at SparkLeftOutJoin.java:89)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting ResultStage 5 (MapPartitionsRDD[12] at mapValues at SparkLeftOutJoin.java:82), which has no missing parents
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_5 stored as values in memory (estimated size 9.3 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.7 KB, free 895.9 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Added broadcast_5_piece0 in memory on TKK-YXKJ:49554 (size: 4.7 KB, free: 896.3 MB)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Created broadcast 5 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:46:18[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 5 (MapPartitionsRDD[12] at mapValues at SparkLeftOutJoin.java:82) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:46:18[ INFO](Logging.scala:54) Adding task set 5.0 with 4 tasks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 0.0 in stage 5.0 (TID 12, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 1.0 in stage 5.0 (TID 13, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 2.0 in stage 5.0 (TID 14, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Starting task 3.0 in stage 5.0 (TID 15, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 0.0 in stage 5.0 (TID 12)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 2.0 in stage 5.0 (TID 14)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 1.0 in stage 5.0 (TID 13)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Running task 3.0 in stage 5.0 (TID 15)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 5.0 (TID 14). 1180 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 5.0 (TID 15). 1198 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 5.0 (TID 13). 1189 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 5.0 (TID 12). 1180 bytes result sent to driver
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 2.0 in stage 5.0 (TID 14) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 3.0 in stage 5.0 (TID 15) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 1.0 in stage 5.0 (TID 13) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Finished task 0.0 in stage 5.0 (TID 12) in 20 ms on localhost (executor driver) (4/4)
2019-11-21 16:46:18[ INFO](Logging.scala:54) Removed TaskSet 5.0, whose tasks have all completed, from pool 
2019-11-21 16:46:18[ INFO](Logging.scala:54) ResultStage 5 (collect at SparkLeftOutJoin.java:89) finished in 0.030 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) Job 1 finished: collect at SparkLeftOutJoin.java:89, took 0.024383 s
2019-11-21 16:46:18[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:46:18[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:46:18[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:46:18[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:46:18[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:46:18[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:46:18[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:46:18[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:46:18[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:46:18[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:46:18[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-c55ced9a-8c49-4112-8166-53be8848f665
2019-11-21 16:53:20[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:53:20[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:53:20[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:53:20[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:53:20[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:53:20[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:53:20[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:53:22[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49762.
2019-11-21 16:53:22[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:53:22[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:53:22[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:53:22[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:53:22[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-9bd4d3a6-1e15-458e-b796-529a702e03ac
2019-11-21 16:53:22[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:53:22[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:53:22[ INFO](Log.java:192) Logging initialized @3259ms
2019-11-21 16:53:23[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:53:23[ INFO](Server.java:419) Started @3307ms
2019-11-21 16:53:23[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:53:23[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:53:23[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49803.
2019-11-21 16:53:23[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49803
2019-11-21 16:53:23[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:53:23[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49803, None)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49803 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49803, None)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49803, None)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49803, None)
2019-11-21 16:53:23[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:53:23[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 214.6 KB, free 896.2 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.4 KB, free 896.2 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49803 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Created broadcast 0 from textFile at SparkLeftOutJoin.java:36
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 214.7 KB, free 896.0 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 20.4 KB, free 895.9 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49803 (size: 20.4 KB, free: 896.4 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Created broadcast 1 from textFile at SparkLeftOutJoin.java:43
2019-11-21 16:53:23[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:53:23[ INFO](FileInputFormat.java:247) Total input paths to process : 1
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:54
2019-11-21 16:53:23[ INFO](Logging.scala:54) Registering RDD 6 (union at SparkLeftOutJoin.java:50)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Got job 0 (collect at SparkLeftOutJoin.java:54) with 4 output partitions
2019-11-21 16:53:23[ INFO](Logging.scala:54) Final stage: ResultStage 1 (collect at SparkLeftOutJoin.java:54)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 0)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 0)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Submitting ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:50), which has no missing parents
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 895.9 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.8 KB, free 895.9 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:49803 (size: 3.8 KB, free: 896.4 MB)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:53:23[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 0 (UnionRDD[6] at union at SparkLeftOutJoin.java:50) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:53:23[ INFO](Logging.scala:54) Adding task set 0.0 with 4 tasks
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 8002 bytes)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Running task 2.0 in stage 0.0 (TID 2)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Running task 1.0 in stage 0.0 (TID 1)
2019-11-21 16:53:23[ INFO](Logging.scala:54) Running task 3.0 in stage 0.0 (TID 3)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:0+80
2019-11-21 16:53:24[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union2:80+80
2019-11-21 16:53:24[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:0+27
2019-11-21 16:53:24[ INFO](Logging.scala:54) Input split: file:/D:/project/sparkTotal/jvm/java8/union1:27+28
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1). 937 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2). 937 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3). 937 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 937 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 0.0 (TID 1) in 122 ms on localhost (executor driver) (1/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 0.0 (TID 2) in 122 ms on localhost (executor driver) (2/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 132 ms on localhost (executor driver) (3/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 0.0 (TID 3) in 122 ms on localhost (executor driver) (4/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:53:24[ INFO](Logging.scala:54) ShuffleMapStage 0 (union at SparkLeftOutJoin.java:50) finished in 0.172 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:53:24[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:53:24[ INFO](Logging.scala:54) waiting: Set(ResultStage 1)
2019-11-21 16:53:24[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[8] at groupByKey at SparkLeftOutJoin.java:53), which has no missing parents
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 8.1 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.3 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:49803 (size: 4.3 KB, free: 896.4 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at groupByKey at SparkLeftOutJoin.java:53) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:53:24[ INFO](Logging.scala:54) Adding task set 1.0 with 4 tasks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 1.0 in stage 1.0 (TID 5)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 2.0 in stage 1.0 (TID 6)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 3.0 in stage 1.0 (TID 7)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 10 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7). 3636 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5). 3702 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4). 3773 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6). 3618 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 1.0 (TID 7) in 50 ms on localhost (executor driver) (1/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 1.0 (TID 6) in 50 ms on localhost (executor driver) (2/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 4) in 50 ms on localhost (executor driver) (3/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 1.0 (TID 5) in 50 ms on localhost (executor driver) (4/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:53:24[ INFO](Logging.scala:54) ResultStage 1 (collect at SparkLeftOutJoin.java:54) finished in 0.060 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Job 0 finished: collect at SparkLeftOutJoin.java:54, took 0.284459 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:78
2019-11-21 16:53:24[ INFO](Logging.scala:54) Registering RDD 9 (flatMapToPair at SparkLeftOutJoin.java:57)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Got job 1 (collect at SparkLeftOutJoin.java:78) with 4 output partitions
2019-11-21 16:53:24[ INFO](Logging.scala:54) Final stage: ResultStage 4 (collect at SparkLeftOutJoin.java:78)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 3)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Missing parents: List(ShuffleMapStage 3)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting ShuffleMapStage 3 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:57), which has no missing parents
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 8.5 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:49803 (size: 4.4 KB, free: 896.3 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[9] at flatMapToPair at SparkLeftOutJoin.java:57) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:53:24[ INFO](Logging.scala:54) Adding task set 3.0 with 4 tasks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 0.0 in stage 3.0 (TID 8, localhost, executor driver, partition 0, ANY, 7651 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 1.0 in stage 3.0 (TID 9, localhost, executor driver, partition 1, ANY, 7651 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 2.0 in stage 3.0 (TID 10, localhost, executor driver, partition 2, ANY, 7651 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 3.0 in stage 3.0 (TID 11, localhost, executor driver, partition 3, ANY, 7651 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 3.0 in stage 3.0 (TID 11)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 2.0 in stage 3.0 (TID 10)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 0.0 in stage 3.0 (TID 8)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 1.0 in stage 3.0 (TID 9)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 4 non-empty blocks including 4 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 3.0 (TID 10). 1109 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 3.0 (TID 10) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 3.0 (TID 11). 1195 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 3.0 (TID 11) in 20 ms on localhost (executor driver) (2/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 8). 1238 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 8) in 20 ms on localhost (executor driver) (3/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 3.0 (TID 9). 1238 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 3.0 (TID 9) in 20 ms on localhost (executor driver) (4/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-11-21 16:53:24[ INFO](Logging.scala:54) ShuffleMapStage 3 (flatMapToPair at SparkLeftOutJoin.java:57) finished in 0.040 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) looking for newly runnable stages
2019-11-21 16:53:24[ INFO](Logging.scala:54) running: Set()
2019-11-21 16:53:24[ INFO](Logging.scala:54) waiting: Set(ResultStage 4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) failed: Set()
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting ResultStage 4 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:77), which has no missing parents
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Added broadcast_5_piece0 in memory on TKK-YXKJ:49803 (size: 4.6 KB, free: 896.3 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Created broadcast 5 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at groupByKey at SparkLeftOutJoin.java:77) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:53:24[ INFO](Logging.scala:54) Adding task set 4.0 with 4 tasks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 0.0 in stage 4.0 (TID 12, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 1.0 in stage 4.0 (TID 13, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 2.0 in stage 4.0 (TID 14, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 3.0 in stage 4.0 (TID 15, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 3.0 in stage 4.0 (TID 15)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 0.0 in stage 4.0 (TID 12)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 2.0 in stage 4.0 (TID 14)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 1.0 in stage 4.0 (TID 13)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 4.0 (TID 14). 3569 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 4.0 (TID 12). 3569 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 4.0 (TID 13). 3628 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 4.0 (TID 15). 3632 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 4.0 (TID 12) in 10 ms on localhost (executor driver) (1/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 4.0 (TID 13) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 4.0 (TID 14) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 4.0 (TID 15) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Removed TaskSet 4.0, whose tasks have all completed, from pool 
2019-11-21 16:53:24[ INFO](Logging.scala:54) ResultStage 4 (collect at SparkLeftOutJoin.java:78) finished in 0.010 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Job 1 finished: collect at SparkLeftOutJoin.java:78, took 0.052174 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting job: collect at SparkLeftOutJoin.java:91
2019-11-21 16:53:24[ INFO](Logging.scala:54) Got job 2 (collect at SparkLeftOutJoin.java:91) with 4 output partitions
2019-11-21 16:53:24[ INFO](Logging.scala:54) Final stage: ResultStage 7 (collect at SparkLeftOutJoin.java:91)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Parents of final stage: List(ShuffleMapStage 6)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting ResultStage 7 (MapPartitionsRDD[12] at mapValues at SparkLeftOutJoin.java:84), which has no missing parents
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_6 stored as values in memory (estimated size 9.3 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.7 KB, free 895.9 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Added broadcast_6_piece0 in memory on TKK-YXKJ:49803 (size: 4.7 KB, free: 896.3 MB)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Created broadcast 6 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:53:24[ INFO](Logging.scala:54) Submitting 4 missing tasks from ResultStage 7 (MapPartitionsRDD[12] at mapValues at SparkLeftOutJoin.java:84) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
2019-11-21 16:53:24[ INFO](Logging.scala:54) Adding task set 7.0 with 4 tasks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 1.0 in stage 7.0 (TID 17, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 2.0 in stage 7.0 (TID 18, localhost, executor driver, partition 2, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Starting task 3.0 in stage 7.0 (TID 19, localhost, executor driver, partition 3, ANY, 7662 bytes)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 0.0 in stage 7.0 (TID 16)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 2.0 in stage 7.0 (TID 18)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 3.0 in stage 7.0 (TID 19)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Running task 1.0 in stage 7.0 (TID 17)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Started 0 remote fetches in 0 ms
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 7.0 (TID 18). 1180 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 7.0 (TID 19). 1198 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 7.0 (TID 16). 1180 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 7.0 (TID 17). 1189 bytes result sent to driver
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 0.0 in stage 7.0 (TID 16) in 0 ms on localhost (executor driver) (1/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 3.0 in stage 7.0 (TID 19) in 10 ms on localhost (executor driver) (2/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 2.0 in stage 7.0 (TID 18) in 10 ms on localhost (executor driver) (3/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Finished task 1.0 in stage 7.0 (TID 17) in 10 ms on localhost (executor driver) (4/4)
2019-11-21 16:53:24[ INFO](Logging.scala:54) Removed TaskSet 7.0, whose tasks have all completed, from pool 
2019-11-21 16:53:24[ INFO](Logging.scala:54) ResultStage 7 (collect at SparkLeftOutJoin.java:91) finished in 0.020 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Job 2 finished: collect at SparkLeftOutJoin.java:91, took 0.016339 s
2019-11-21 16:53:24[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:53:24[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:53:24[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:53:24[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:53:24[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:53:24[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:53:24[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:53:24[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:53:24[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:53:24[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:53:24[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-76b4e6ae-1959-485e-92e8-4624c8e30693
2019-11-21 16:56:13[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:56:14[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:56:14[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:56:14[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:56:14[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:56:14[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:56:14[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:56:15[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 49909.
2019-11-21 16:56:15[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:56:15[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:56:15[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:56:15[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:56:16[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-cb6f6550-f452-4503-a6b6-43ade1673bfd
2019-11-21 16:56:16[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:56:16[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:56:16[ INFO](Log.java:192) Logging initialized @3316ms
2019-11-21 16:56:16[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:56:16[ INFO](Server.java:419) Started @3364ms
2019-11-21 16:56:16[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:56:16[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:56:16[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:56:16[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49950.
2019-11-21 16:56:16[ INFO](Logging.scala:54) Server created on TKK-YXKJ:49950
2019-11-21 16:56:16[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:56:16[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 49950, None)
2019-11-21 16:56:16[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:49950 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 49950, None)
2019-11-21 16:56:16[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 49950, None)
2019-11-21 16:56:16[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 49950, None)
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:56:16[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 16:56:16[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 16:56:16[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 16:56:17[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 16:56:18[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 16:56:18[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 16:56:18[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 16:56:18[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 16:56:19[ INFO](Logging.scala:54) Code generated in 159.3493 ms
2019-11-21 16:56:19[ INFO](Logging.scala:54) Code generated in 6.635 ms
2019-11-21 16:56:19[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:49950 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:103
2019-11-21 16:56:19[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 16:56:19[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:103
2019-11-21 16:56:19[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:103) with 1 output partitions
2019-11-21 16:56:19[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:103)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 16:56:19[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 16:56:19[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:103), which has no missing parents
2019-11-21 16:56:19[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:49950 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:56:19[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:103) (first 15 tasks are for partitions Vector(0))
2019-11-21 16:56:19[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 16:56:19[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 16:56:19[ INFO](Logging.scala:54) Code generated in 6.6385 ms
2019-11-21 16:56:19[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1257 bytes result sent to driver
2019-11-21 16:56:19[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 110 ms on localhost (executor driver) (1/1)
2019-11-21 16:56:19[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:56:19[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:103) finished in 0.170 s
2019-11-21 16:56:19[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:103, took 0.192596 s
2019-11-21 16:56:19[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:56:19[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:56:19[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:56:19[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:56:19[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:56:19[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:56:19[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:56:19[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:56:19[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:56:19[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:56:19[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-17eb5fcb-d42b-4f30-bd23-4dcba5212a0e
2019-11-21 16:57:27[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 16:57:27[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 16:57:27[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 16:57:27[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 16:57:27[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 16:57:27[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 16:57:27[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 16:57:29[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 50014.
2019-11-21 16:57:29[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 16:57:29[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 16:57:29[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 16:57:29[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 16:57:29[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-7b16126e-d986-4627-8a77-c03d10cc64aa
2019-11-21 16:57:29[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 16:57:29[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 16:57:29[ INFO](Log.java:192) Logging initialized @3264ms
2019-11-21 16:57:29[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 16:57:29[ INFO](Server.java:419) Started @3312ms
2019-11-21 16:57:29[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:57:29[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 16:57:30[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 16:57:30[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50055.
2019-11-21 16:57:30[ INFO](Logging.scala:54) Server created on TKK-YXKJ:50055
2019-11-21 16:57:30[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 16:57:30[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 50055, None)
2019-11-21 16:57:30[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:50055 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 50055, None)
2019-11-21 16:57:30[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 50055, None)
2019-11-21 16:57:30[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 50055, None)
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 16:57:30[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 16:57:30[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 16:57:30[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 16:57:32[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 16:57:32[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 16:57:32[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 16:57:32[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 16:57:32[ INFO](Logging.scala:54) Code generated in 142.9166 ms
2019-11-21 16:57:32[ INFO](Logging.scala:54) Code generated in 6.3738 ms
2019-11-21 16:57:32[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:50055 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:104
2019-11-21 16:57:32[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 16:57:32[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:104
2019-11-21 16:57:32[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:104) with 1 output partitions
2019-11-21 16:57:32[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:104)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 16:57:32[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 16:57:32[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:104), which has no missing parents
2019-11-21 16:57:32[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:50055 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:57:32[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:104) (first 15 tasks are for partitions Vector(0))
2019-11-21 16:57:32[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 16:57:32[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 16:57:32[ INFO](Logging.scala:54) Code generated in 7.7662 ms
2019-11-21 16:57:32[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1214 bytes result sent to driver
2019-11-21 16:57:32[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 100 ms on localhost (executor driver) (1/1)
2019-11-21 16:57:32[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 16:57:32[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:104) finished in 0.171 s
2019-11-21 16:57:32[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:104, took 0.204842 s
2019-11-21 16:57:32[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 16:57:32[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 16:57:32[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 16:57:32[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 16:57:33[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.9 KB, free 895.9 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:50055 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Created broadcast 2 from show at SparkLeftOutJoin.java:105
2019-11-21 16:57:33[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 16:57:33[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:105
2019-11-21 16:57:33[ INFO](Logging.scala:54) Got job 1 (show at SparkLeftOutJoin.java:105) with 1 output partitions
2019-11-21 16:57:33[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SparkLeftOutJoin.java:105)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 16:57:33[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 16:57:33[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:105), which has no missing parents
2019-11-21 16:57:33[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 895.9 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.9 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:50055 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 16:57:33[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:105) (first 15 tasks are for partitions Vector(0))
2019-11-21 16:57:33[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-21 16:57:33[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 16:57:33[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1224 bytes result sent to driver
2019-11-21 16:57:33[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 16:57:33[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 16:57:33[ INFO](Logging.scala:54) ResultStage 1 (show at SparkLeftOutJoin.java:105) finished in 0.019 s
2019-11-21 16:57:33[ INFO](Logging.scala:54) Job 1 finished: show at SparkLeftOutJoin.java:105, took 0.017271 s
2019-11-21 16:57:33[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 16:57:33[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 16:57:33[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 16:57:33[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 16:57:33[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 16:57:33[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 16:57:33[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 16:57:33[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 16:57:33[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 16:57:33[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 16:57:33[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-f8084ee3-bb1f-40c3-9b88-20131ce2c939
2019-11-21 17:02:08[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 17:02:08[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 17:02:08[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 17:02:08[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 17:02:08[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 17:02:08[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 17:02:08[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 17:02:10[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 50196.
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 17:02:10[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 17:02:10[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 17:02:10[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-4171c73c-3c5c-4ee2-a0c4-213e7de81177
2019-11-21 17:02:10[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 17:02:10[ INFO](Log.java:192) Logging initialized @3158ms
2019-11-21 17:02:10[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 17:02:10[ INFO](Server.java:419) Started @3206ms
2019-11-21 17:02:10[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:02:10[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 17:02:10[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 17:02:10[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 17:02:10[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50237.
2019-11-21 17:02:10[ INFO](Logging.scala:54) Server created on TKK-YXKJ:50237
2019-11-21 17:02:10[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 50237, None)
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:50237 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 50237, None)
2019-11-21 17:02:10[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 50237, None)
2019-11-21 17:02:10[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 50237, None)
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 17:02:11[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 17:02:11[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 17:02:11[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 17:02:13[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:13[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:13[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:13[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:13[ INFO](Logging.scala:54) Code generated in 261.5766 ms
2019-11-21 17:02:13[ INFO](Logging.scala:54) Code generated in 6.5871 ms
2019-11-21 17:02:13[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:50237 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:106
2019-11-21 17:02:13[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:13[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:106
2019-11-21 17:02:13[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:106) with 1 output partitions
2019-11-21 17:02:13[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:106)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:13[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:13[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106), which has no missing parents
2019-11-21 17:02:13[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:50237 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:13[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:13[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 17:02:13[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 17:02:13[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 17:02:14[ INFO](Logging.scala:54) Code generated in 7.0289 ms
2019-11-21 17:02:14[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1257 bytes result sent to driver
2019-11-21 17:02:14[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 112 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 17:02:14[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:106) finished in 0.162 s
2019-11-21 17:02:14[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:106, took 0.198251 s
2019-11-21 17:02:14[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:14[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:14[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:14[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:14[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.9 KB, free 895.9 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:50237 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Created broadcast 2 from show at SparkLeftOutJoin.java:107
2019-11-21 17:02:14[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:14[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:107
2019-11-21 17:02:14[ INFO](Logging.scala:54) Got job 1 (show at SparkLeftOutJoin.java:107) with 1 output partitions
2019-11-21 17:02:14[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SparkLeftOutJoin.java:107)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:14[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:14[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107), which has no missing parents
2019-11-21 17:02:14[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 895.9 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.9 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:50237 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:14[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:14[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-21 17:02:14[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 17:02:14[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1267 bytes result sent to driver
2019-11-21 17:02:14[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:14[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 17:02:14[ INFO](Logging.scala:54) ResultStage 1 (show at SparkLeftOutJoin.java:107) finished in 0.019 s
2019-11-21 17:02:14[ INFO](Logging.scala:54) Job 1 finished: show at SparkLeftOutJoin.java:107, took 0.021538 s
2019-11-21 17:02:14[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 17:02:14[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:02:14[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 17:02:14[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 17:02:14[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 17:02:14[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 17:02:14[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 17:02:14[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 17:02:14[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 17:02:14[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 17:02:14[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-722eb5c3-a1cb-4b75-bbca-70de2a8ba5f8
2019-11-21 17:02:44[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 17:02:45[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 17:02:45[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 17:02:45[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 17:02:45[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 17:02:45[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 17:02:45[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 17:02:46[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 50287.
2019-11-21 17:02:46[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 17:02:46[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 17:02:46[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 17:02:46[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 17:02:47[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-6cb3ee27-53d5-4f2b-b662-3fb00c78d72a
2019-11-21 17:02:47[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 17:02:47[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 17:02:47[ INFO](Log.java:192) Logging initialized @3305ms
2019-11-21 17:02:47[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 17:02:47[ INFO](Server.java:419) Started @3353ms
2019-11-21 17:02:47[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:02:47[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 17:02:47[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 17:02:47[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50328.
2019-11-21 17:02:47[ INFO](Logging.scala:54) Server created on TKK-YXKJ:50328
2019-11-21 17:02:47[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 17:02:47[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 50328, None)
2019-11-21 17:02:47[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:50328 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 50328, None)
2019-11-21 17:02:47[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 50328, None)
2019-11-21 17:02:47[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 50328, None)
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 17:02:47[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 17:02:47[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 17:02:47[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 17:02:48[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 17:02:49[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:49[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:49[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:49[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Code generated in 227.424 ms
2019-11-21 17:02:50[ INFO](Logging.scala:54) Code generated in 6.6397 ms
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:50328 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:106
2019-11-21 17:02:50[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:106
2019-11-21 17:02:50[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:106) with 1 output partitions
2019-11-21 17:02:50[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:106)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106), which has no missing parents
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:50328 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:50[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 17:02:50[ INFO](Logging.scala:54) Code generated in 6.7481 ms
2019-11-21 17:02:50[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1257 bytes result sent to driver
2019-11-21 17:02:50[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 90 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 17:02:50[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:106) finished in 0.171 s
2019-11-21 17:02:50[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:106, took 0.198892 s
2019-11-21 17:02:50[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:50[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.9 KB, free 895.9 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:50328 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 2 from show at SparkLeftOutJoin.java:107
2019-11-21 17:02:50[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:107
2019-11-21 17:02:50[ INFO](Logging.scala:54) Got job 1 (show at SparkLeftOutJoin.java:107) with 1 output partitions
2019-11-21 17:02:50[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SparkLeftOutJoin.java:107)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107), which has no missing parents
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 895.9 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.9 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:50328 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:50[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 17:02:50[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1267 bytes result sent to driver
2019-11-21 17:02:50[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 17:02:50[ INFO](Logging.scala:54) ResultStage 1 (show at SparkLeftOutJoin.java:107) finished in 0.021 s
2019-11-21 17:02:50[ INFO](Logging.scala:54) Job 1 finished: show at SparkLeftOutJoin.java:107, took 0.026609 s
2019-11-21 17:02:50[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:50[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 219.8 KB, free 895.7 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.7 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:50328 (size: 20.6 KB, free: 896.3 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 4 from show at SparkLeftOutJoin.java:109
2019-11-21 17:02:50[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:109
2019-11-21 17:02:50[ INFO](Logging.scala:54) Got job 2 (show at SparkLeftOutJoin.java:109) with 1 output partitions
2019-11-21 17:02:50[ INFO](Logging.scala:54) Final stage: ResultStage 2 (show at SparkLeftOutJoin.java:109)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at show at SparkLeftOutJoin.java:109), which has no missing parents
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_5 stored as values in memory (estimated size 7.4 KB, free 895.7 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.7 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Added broadcast_5_piece0 in memory on TKK-YXKJ:50328 (size: 4.0 KB, free: 896.3 MB)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Created broadcast 5 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:50[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at SparkLeftOutJoin.java:109) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:50[ INFO](Logging.scala:54) Adding task set 2.0 with 1 tasks
2019-11-21 17:02:50[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 2)
2019-11-21 17:02:50[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 17:02:50[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 2). 1085 bytes result sent to driver
2019-11-21 17:02:51[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 17:02:51[ INFO](Logging.scala:54) ResultStage 2 (show at SparkLeftOutJoin.java:109) finished in 0.020 s
2019-11-21 17:02:51[ INFO](Logging.scala:54) Job 2 finished: show at SparkLeftOutJoin.java:109, took 0.018717 s
2019-11-21 17:02:51[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:02:51[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:02:51[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:02:51[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 86
2019-11-21 17:02:51[ INFO](Logging.scala:54) Block broadcast_6 stored as values in memory (estimated size 219.8 KB, free 895.4 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed broadcast_4_piece0 on TKK-YXKJ:50328 in memory (size: 20.6 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.7 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Added broadcast_6_piece0 in memory on TKK-YXKJ:50328 (size: 20.6 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Created broadcast 6 from show at SparkLeftOutJoin.java:111
2019-11-21 17:02:51[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 54
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 76
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 67
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 10
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 39
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 30
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 16
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 58
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 82
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 8
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 40
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed broadcast_1_piece0 on TKK-YXKJ:50328 in memory (size: 4.0 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 77
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed broadcast_5_piece0 on TKK-YXKJ:50328 in memory (size: 4.0 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:111
2019-11-21 17:02:51[ INFO](Logging.scala:54) Got job 3 (show at SparkLeftOutJoin.java:111) with 1 output partitions
2019-11-21 17:02:51[ INFO](Logging.scala:54) Final stage: ResultStage 3 (show at SparkLeftOutJoin.java:111)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:02:51[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:02:51[ INFO](Logging.scala:54) Submitting ResultStage 3 (MapPartitionsRDD[15] at show at SparkLeftOutJoin.java:111), which has no missing parents
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 52
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 62
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 70
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 65
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 42
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 83
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 61
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 57
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 50
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 43
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 24
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 79
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 81
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 53
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 7
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 27
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 33
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 15
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 85
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 11
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 71
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 89
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 73
2019-11-21 17:02:51[ INFO](Logging.scala:54) Block broadcast_7 stored as values in memory (estimated size 7.4 KB, free 895.7 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 35
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 44
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 45
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 68
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 46
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 66
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 47
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 78
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 28
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 6
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 49
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 5
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 87
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 26
2019-11-21 17:02:51[ INFO](Logging.scala:54) Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.7 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed broadcast_3_piece0 on TKK-YXKJ:50328 in memory (size: 4.0 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Added broadcast_7_piece0 in memory on TKK-YXKJ:50328 (size: 4.0 KB, free: 896.3 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Created broadcast 7 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 38
2019-11-21 17:02:51[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at SparkLeftOutJoin.java:111) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:02:51[ INFO](Logging.scala:54) Adding task set 3.0 with 1 tasks
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 22
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 17
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 32
2019-11-21 17:02:51[ INFO](Logging.scala:54) Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Running task 0.0 in stage 3.0 (TID 3)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed broadcast_2_piece0 on TKK-YXKJ:50328 in memory (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 18
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 72
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 60
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 88
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 41
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 64
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 84
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 19
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 20
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 31
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 13
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 48
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 80
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 9
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 59
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 69
2019-11-21 17:02:51[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 56
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 23
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 12
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 25
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 37
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 63
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 21
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 74
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 36
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 34
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 14
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 29
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 75
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 51
2019-11-21 17:02:51[ INFO](Logging.scala:54) Cleaned accumulator 55
2019-11-21 17:02:51[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 3). 1224 bytes result sent to driver
2019-11-21 17:02:51[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 3) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 17:02:51[ INFO](Logging.scala:54) Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-11-21 17:02:51[ INFO](Logging.scala:54) ResultStage 3 (show at SparkLeftOutJoin.java:111) finished in 0.020 s
2019-11-21 17:02:51[ INFO](Logging.scala:54) Job 3 finished: show at SparkLeftOutJoin.java:111, took 0.018747 s
2019-11-21 17:02:51[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 17:02:51[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:02:51[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 17:02:51[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 17:02:51[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 17:02:51[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 17:02:51[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 17:02:51[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 17:02:51[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 17:02:51[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 17:02:51[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-84cb27f1-7140-4a6f-9668-27fc9e56a2ba
2019-11-21 17:06:22[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 17:06:22[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 17:06:23[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 17:06:23[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 17:06:23[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 17:06:23[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 17:06:23[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 17:06:24[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 50445.
2019-11-21 17:06:24[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 17:06:24[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 17:06:24[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 17:06:24[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 17:06:25[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-a90fcb7c-a5d4-4e71-aa1d-032c890f8498
2019-11-21 17:06:25[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 17:06:25[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 17:06:25[ INFO](Log.java:192) Logging initialized @3213ms
2019-11-21 17:06:25[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 17:06:25[ INFO](Server.java:419) Started @3276ms
2019-11-21 17:06:25[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:06:25[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 17:06:25[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 17:06:25[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 50486.
2019-11-21 17:06:25[ INFO](Logging.scala:54) Server created on TKK-YXKJ:50486
2019-11-21 17:06:25[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 17:06:25[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 50486, None)
2019-11-21 17:06:25[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:50486 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 50486, None)
2019-11-21 17:06:25[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 50486, None)
2019-11-21 17:06:25[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 50486, None)
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 17:06:25[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 17:06:25[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 17:06:25[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 17:06:26[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 17:06:27[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:06:27[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:06:27[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:06:27[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:06:28[ INFO](Logging.scala:54) Code generated in 258.5726 ms
2019-11-21 17:06:28[ INFO](Logging.scala:54) Code generated in 6.9074 ms
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:50486 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:106
2019-11-21 17:06:28[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:06:28[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:106
2019-11-21 17:06:28[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:106) with 1 output partitions
2019-11-21 17:06:28[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:106)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:06:28[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:06:28[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106), which has no missing parents
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:50486 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:06:28[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:06:28[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 17:06:28[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 17:06:28[ INFO](Logging.scala:54) Code generated in 9.2852 ms
2019-11-21 17:06:28[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1214 bytes result sent to driver
2019-11-21 17:06:28[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 139 ms on localhost (executor driver) (1/1)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 17:06:28[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:106) finished in 0.211 s
2019-11-21 17:06:28[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:106, took 0.242934 s
2019-11-21 17:06:28[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 17:06:28[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 17:06:28[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 17:06:28[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.9 KB, free 895.9 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:50486 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Created broadcast 2 from show at SparkLeftOutJoin.java:107
2019-11-21 17:06:28[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 17:06:28[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:107
2019-11-21 17:06:28[ INFO](Logging.scala:54) Got job 1 (show at SparkLeftOutJoin.java:107) with 1 output partitions
2019-11-21 17:06:28[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SparkLeftOutJoin.java:107)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 17:06:28[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 17:06:28[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107), which has no missing parents
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 895.9 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.9 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:50486 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 17:06:28[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107) (first 15 tasks are for partitions Vector(0))
2019-11-21 17:06:28[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-21 17:06:28[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 17:06:28[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1267 bytes result sent to driver
2019-11-21 17:06:28[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 17:06:28[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 17:06:28[ INFO](Logging.scala:54) ResultStage 1 (show at SparkLeftOutJoin.java:107) finished in 0.020 s
2019-11-21 17:06:28[ INFO](Logging.scala:54) Job 1 finished: show at SparkLeftOutJoin.java:107, took 0.023661 s
2019-11-21 17:06:28[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 17:06:28[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 17:06:28[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 17:06:28[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 17:06:28[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 17:06:28[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 17:06:28[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 17:06:28[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 17:06:28[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 17:06:28[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 17:06:28[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-bd18be90-cfb4-4582-99f7-b8535f8c09ee
2019-11-21 18:57:31[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-21 18:57:31[ INFO](Logging.scala:54) Submitted application: TestLeftJoin
2019-11-21 18:57:31[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-21 18:57:31[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-21 18:57:31[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-21 18:57:31[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-21 18:57:31[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-21 18:57:33[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 51834.
2019-11-21 18:57:33[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-21 18:57:33[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-21 18:57:33[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-21 18:57:33[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-21 18:57:33[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-77ca6e8e-8be4-4ec0-ba1d-5949c098f64c
2019-11-21 18:57:33[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-21 18:57:33[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-21 18:57:34[ INFO](Log.java:192) Logging initialized @3188ms
2019-11-21 18:57:34[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-21 18:57:34[ INFO](Server.java:419) Started @3235ms
2019-11-21 18:57:34[ INFO](AbstractConnector.java:278) Started ServerConnector@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 18:57:34[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a3e3e8b{/jobs,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@33617539{/jobs/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2c177f9e{/jobs/job,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@209775a9{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@18e7143f{/stages,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f9b7332{/stages/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74cec793{/stages/stage,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1bdf8190{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@192f2f27{/stages/pool,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@8a589a2{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c65a5ef{/storage,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b672aa8{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2fab4aff{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@ec0c838{/environment,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@6e46d9f4{/environment/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5cc69cfe{/executors,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@29cfd92b{/executors/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@21c64522{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7997b197{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@11dee337{/static,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/api,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-21 18:57:34[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-21 18:57:34[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51876.
2019-11-21 18:57:34[ INFO](Logging.scala:54) Server created on TKK-YXKJ:51876
2019-11-21 18:57:34[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-21 18:57:34[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 51876, None)
2019-11-21 18:57:34[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:51876 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 51876, None)
2019-11-21 18:57:34[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 51876, None)
2019-11-21 18:57:34[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 51876, None)
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@547c04c4{/metrics/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ WARN](Logging.scala:66) Using an existing SparkContext; some configuration may not take effect.
2019-11-21 18:57:34[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-21 18:57:34[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@c3fa05a{/SQL,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7b44b63d{/SQL/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@17ae7628{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@1136b469{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@693e4d19{/static/sql,null,AVAILABLE,@Spark}
2019-11-21 18:57:34[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-21 18:57:36[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 18:57:36[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 18:57:36[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 18:57:36[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 18:57:36[ INFO](Logging.scala:54) Code generated in 236.7945 ms
2019-11-21 18:57:36[ INFO](Logging.scala:54) Code generated in 6.7464 ms
2019-11-21 18:57:36[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.9 KB, free 896.2 MB)
2019-11-21 18:57:36[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-21 18:57:36[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:51876 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 18:57:36[ INFO](Logging.scala:54) Created broadcast 0 from show at SparkLeftOutJoin.java:106
2019-11-21 18:57:36[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 18:57:36[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:106
2019-11-21 18:57:36[ INFO](Logging.scala:54) Got job 0 (show at SparkLeftOutJoin.java:106) with 1 output partitions
2019-11-21 18:57:36[ INFO](Logging.scala:54) Final stage: ResultStage 0 (show at SparkLeftOutJoin.java:106)
2019-11-21 18:57:36[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 18:57:36[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106), which has no missing parents
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 7.4 KB, free 896.2 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 896.2 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:51876 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at show at SparkLeftOutJoin.java:106) (first 15 tasks are for partitions Vector(0))
2019-11-21 18:57:37[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 18:57:37[ INFO](Logging.scala:54) Code generated in 6.8672 ms
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1257 bytes result sent to driver
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 110 ms on localhost (executor driver) (1/1)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-21 18:57:37[ INFO](Logging.scala:54) ResultStage 0 (show at SparkLeftOutJoin.java:106) finished in 0.171 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Job 0 finished: show at SparkLeftOutJoin.java:106, took 0.199013 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.9 KB, free 895.9 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:51876 (size: 20.6 KB, free: 896.4 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 2 from show at SparkLeftOutJoin.java:107
2019-11-21 18:57:37[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:107
2019-11-21 18:57:37[ INFO](Logging.scala:54) Got job 1 (show at SparkLeftOutJoin.java:107) with 1 output partitions
2019-11-21 18:57:37[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SparkLeftOutJoin.java:107)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107), which has no missing parents
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 895.9 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.9 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:51876 (size: 4.0 KB, free: 896.4 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at SparkLeftOutJoin.java:107) (first 15 tasks are for partitions Vector(0))
2019-11-21 18:57:37[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1267 bytes result sent to driver
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-21 18:57:37[ INFO](Logging.scala:54) ResultStage 1 (show at SparkLeftOutJoin.java:107) finished in 0.010 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Job 1 finished: show at SparkLeftOutJoin.java:107, took 0.020480 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_4 stored as values in memory (estimated size 219.8 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_4_piece0 in memory on TKK-YXKJ:51876 (size: 20.6 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 4 from show at SparkLeftOutJoin.java:109
2019-11-21 18:57:37[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:109
2019-11-21 18:57:37[ INFO](Logging.scala:54) Got job 2 (show at SparkLeftOutJoin.java:109) with 1 output partitions
2019-11-21 18:57:37[ INFO](Logging.scala:54) Final stage: ResultStage 2 (show at SparkLeftOutJoin.java:109)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting ResultStage 2 (MapPartitionsRDD[11] at show at SparkLeftOutJoin.java:109), which has no missing parents
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_5 stored as values in memory (estimated size 7.4 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_5_piece0 in memory on TKK-YXKJ:51876 (size: 4.0 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 5 from broadcast at DAGScheduler.scala:1161
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at show at SparkLeftOutJoin.java:109) (first 15 tasks are for partitions Vector(0))
2019-11-21 18:57:37[ INFO](Logging.scala:54) Adding task set 2.0 with 1 tasks
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 49
2019-11-21 18:57:37[ INFO](Logging.scala:54) Running task 0.0 in stage 2.0 (TID 2)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 6
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 7
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 9
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 38
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 5
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 8
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 36
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 10
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 21
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 31
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 23
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 56
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 39
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 40
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 51
2019-11-21 18:57:37[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union1, range: 0-55, partition values: [empty row]
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 2). 1128 bytes result sent to driver
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 2.0 (TID 2) in 10 ms on localhost (executor driver) (1/1)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed TaskSet 2.0, whose tasks have all completed, from pool 
2019-11-21 18:57:37[ INFO](Logging.scala:54) ResultStage 2 (show at SparkLeftOutJoin.java:109) finished in 0.045 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Job 2 finished: show at SparkLeftOutJoin.java:109, took 0.044169 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed broadcast_1_piece0 on TKK-YXKJ:51876 in memory (size: 4.0 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 13
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 14
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 33
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 41
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 16
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 15
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 20
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 45
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 54
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 58
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 55
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 42
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 26
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 11
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 19
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 30
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 22
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 43
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 57
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 27
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 29
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed broadcast_3_piece0 on TKK-YXKJ:51876 in memory (size: 4.0 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 32
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 28
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 35
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed broadcast_2_piece0 on TKK-YXKJ:51876 in memory (size: 20.6 KB, free: 896.4 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 53
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 59
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 18
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 24
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 34
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 46
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 37
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 48
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 47
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 17
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 50
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 25
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 52
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 12
2019-11-21 18:57:37[ INFO](Logging.scala:54) Cleaned accumulator 44
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-21 18:57:37[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_6 stored as values in memory (estimated size 219.8 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_6_piece0 in memory on TKK-YXKJ:51876 (size: 20.6 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 6 from show at SparkLeftOutJoin.java:111
2019-11-21 18:57:37[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting job: show at SparkLeftOutJoin.java:111
2019-11-21 18:57:37[ INFO](Logging.scala:54) Got job 3 (show at SparkLeftOutJoin.java:111) with 1 output partitions
2019-11-21 18:57:37[ INFO](Logging.scala:54) Final stage: ResultStage 3 (show at SparkLeftOutJoin.java:111)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Missing parents: List()
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting ResultStage 3 (MapPartitionsRDD[15] at show at SparkLeftOutJoin.java:111), which has no missing parents
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_7 stored as values in memory (estimated size 7.4 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.0 KB, free 895.7 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Added broadcast_7_piece0 in memory on TKK-YXKJ:51876 (size: 4.0 KB, free: 896.3 MB)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Created broadcast 7 from broadcast at DAGScheduler.scala:1161
2019-11-21 18:57:37[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at show at SparkLeftOutJoin.java:111) (first 15 tasks are for partitions Vector(0))
2019-11-21 18:57:37[ INFO](Logging.scala:54) Adding task set 3.0 with 1 tasks
2019-11-21 18:57:37[ INFO](Logging.scala:54) Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8324 bytes)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Running task 0.0 in stage 3.0 (TID 3)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/union2, range: 0-160, partition values: [empty row]
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 3). 1181 bytes result sent to driver
2019-11-21 18:57:37[ INFO](Logging.scala:54) Finished task 0.0 in stage 3.0 (TID 3) in 0 ms on localhost (executor driver) (1/1)
2019-11-21 18:57:37[ INFO](Logging.scala:54) Removed TaskSet 3.0, whose tasks have all completed, from pool 
2019-11-21 18:57:37[ INFO](Logging.scala:54) ResultStage 3 (show at SparkLeftOutJoin.java:111) finished in 0.020 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Job 3 finished: show at SparkLeftOutJoin.java:111, took 0.020399 s
2019-11-21 18:57:37[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-21 18:57:37[ INFO](AbstractConnector.java:318) Stopped Spark@3f23a3a0{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-21 18:57:37[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-21 18:57:37[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-21 18:57:37[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-21 18:57:37[ INFO](Logging.scala:54) BlockManager stopped
2019-11-21 18:57:37[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-21 18:57:37[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-21 18:57:37[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-21 18:57:37[ INFO](Logging.scala:54) Shutdown hook called
2019-11-21 18:57:37[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-84cfd97d-5ee9-4491-af4c-18fc5b3709ed
2019-11-29 16:52:49[ INFO](Logging.scala:54) Running Spark version 2.4.0
2019-11-29 16:52:49[ INFO](Logging.scala:54) Submitted application: sqlParse
2019-11-29 16:52:49[ INFO](Logging.scala:54) Changing view acls to: Token
2019-11-29 16:52:49[ INFO](Logging.scala:54) Changing modify acls to: Token
2019-11-29 16:52:49[ INFO](Logging.scala:54) Changing view acls groups to: 
2019-11-29 16:52:49[ INFO](Logging.scala:54) Changing modify acls groups to: 
2019-11-29 16:52:49[ INFO](Logging.scala:54) SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Token); groups with view permissions: Set(); users  with modify permissions: Set(Token); groups with modify permissions: Set()
2019-11-29 16:52:51[ INFO](Logging.scala:54) Successfully started service 'sparkDriver' on port 52989.
2019-11-29 16:52:51[ INFO](Logging.scala:54) Registering MapOutputTracker
2019-11-29 16:52:51[ INFO](Logging.scala:54) Registering BlockManagerMaster
2019-11-29 16:52:51[ INFO](Logging.scala:54) Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-11-29 16:52:51[ INFO](Logging.scala:54) BlockManagerMasterEndpoint up
2019-11-29 16:52:52[ INFO](Logging.scala:54) Created local directory at C:\Users\Token\AppData\Local\Temp\blockmgr-a4672b94-4333-4562-b45f-1ca97f63f98c
2019-11-29 16:52:52[ INFO](Logging.scala:54) MemoryStore started with capacity 896.4 MB
2019-11-29 16:52:52[ INFO](Logging.scala:54) Registering OutputCommitCoordinator
2019-11-29 16:52:52[ INFO](Log.java:192) Logging initialized @3651ms
2019-11-29 16:52:52[ INFO](Server.java:351) jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-11-29 16:52:52[ INFO](Server.java:419) Started @3716ms
2019-11-29 16:52:52[ INFO](AbstractConnector.java:278) Started ServerConnector@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-29 16:52:52[ INFO](Logging.scala:54) Successfully started service 'SparkUI' on port 4040.
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4f8969b0{/jobs,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@74bdc168{/jobs/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@644c78d4{/jobs/job,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@611f8234{/jobs/job/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7bb3a9fe{/stages,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7cbee484{/stages/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7f811d00{/stages/stage,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@f19c9d2{/stages/stage/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@7807ac2c{/stages/pool,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@b91d8c4{/stages/pool/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4b6166aa{/storage,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a77614d{/storage/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4fd4cae3{/storage/rdd,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a067c25{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a1217f9{/environment,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bde62ff{/environment/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@523424b5{/executors,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@319dead1{/executors/threadDump,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@791cbf87{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@a7e2d9d{/static,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@3bffddff{/,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@66971f6b{/api,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@4a9cc6cb{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@5990e6c5{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](Logging.scala:54) Bound SparkUI to 0.0.0.0, and started at http://TKK-YXKJ:4040
2019-11-29 16:52:52[ INFO](Logging.scala:54) Starting executor ID driver on host localhost
2019-11-29 16:52:52[ INFO](Logging.scala:54) Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53030.
2019-11-29 16:52:52[ INFO](Logging.scala:54) Server created on TKK-YXKJ:53030
2019-11-29 16:52:52[ INFO](Logging.scala:54) Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-11-29 16:52:52[ INFO](Logging.scala:54) Registering BlockManager BlockManagerId(driver, TKK-YXKJ, 53030, None)
2019-11-29 16:52:52[ INFO](Logging.scala:54) Registering block manager TKK-YXKJ:53030 with 896.4 MB RAM, BlockManagerId(driver, TKK-YXKJ, 53030, None)
2019-11-29 16:52:52[ INFO](Logging.scala:54) Registered BlockManager BlockManagerId(driver, TKK-YXKJ, 53030, None)
2019-11-29 16:52:52[ INFO](Logging.scala:54) Initialized BlockManager: BlockManagerId(driver, TKK-YXKJ, 53030, None)
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@58faa93b{/metrics/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](Logging.scala:54) Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/').
2019-11-29 16:52:52[ INFO](Logging.scala:54) Warehouse path is 'file:/D:/project/sparkTotal/jvm/java8/spark-warehouse/'.
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@2d7e1102{/SQL,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@65327f5{/SQL/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@72458efc{/SQL/execution,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@36bc415e{/SQL/execution/json,null,AVAILABLE,@Spark}
2019-11-29 16:52:52[ INFO](ContextHandler.java:781) Started o.s.j.s.ServletContextHandler@72ba28ee{/static/sql,null,AVAILABLE,@Spark}
2019-11-29 16:52:53[ INFO](Logging.scala:54) Registered StateStoreCoordinator endpoint
2019-11-29 16:52:54[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-29 16:52:54[ INFO](Logging.scala:54) Post-Scan Filters: 
2019-11-29 16:52:54[ INFO](Logging.scala:54) Output Data Schema: struct<value: string>
2019-11-29 16:52:54[ INFO](Logging.scala:54) Pushed Filters: 
2019-11-29 16:52:55[ INFO](Logging.scala:54) Code generated in 249.7432 ms
2019-11-29 16:52:55[ INFO](Logging.scala:54) Block broadcast_0 stored as values in memory (estimated size 219.8 KB, free 896.2 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.6 KB, free 896.2 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Added broadcast_0_piece0 in memory on TKK-YXKJ:53030 (size: 20.6 KB, free: 896.4 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Created broadcast 0 from json at SqlParse.java:17
2019-11-29 16:52:55[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-29 16:52:55[ INFO](Logging.scala:54) Starting job: json at SqlParse.java:17
2019-11-29 16:52:55[ INFO](Logging.scala:54) Got job 0 (json at SqlParse.java:17) with 1 output partitions
2019-11-29 16:52:55[ INFO](Logging.scala:54) Final stage: ResultStage 0 (json at SqlParse.java:17)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-29 16:52:55[ INFO](Logging.scala:54) Missing parents: List()
2019-11-29 16:52:55[ INFO](Logging.scala:54) Submitting ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17), which has no missing parents
2019-11-29 16:52:55[ INFO](Logging.scala:54) Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 896.2 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KB, free 896.2 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Added broadcast_1_piece0 in memory on TKK-YXKJ:53030 (size: 5.4 KB, free: 896.4 MB)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-11-29 16:52:55[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at SqlParse.java:17) (first 15 tasks are for partitions Vector(0))
2019-11-29 16:52:55[ INFO](Logging.scala:54) Adding task set 0.0 with 1 tasks
2019-11-29 16:52:55[ INFO](Logging.scala:54) Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Running task 0.0 in stage 0.0 (TID 0)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-29 16:52:55[ INFO](Logging.scala:54) Code generated in 10.4886 ms
2019-11-29 16:52:55[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0). 1932 bytes result sent to driver
2019-11-29 16:52:55[ INFO](Logging.scala:54) Finished task 0.0 in stage 0.0 (TID 0) in 140 ms on localhost (executor driver) (1/1)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-11-29 16:52:55[ INFO](Logging.scala:54) ResultStage 0 (json at SqlParse.java:17) finished in 0.210 s
2019-11-29 16:52:55[ INFO](Logging.scala:54) Job 0 finished: json at SqlParse.java:17, took 0.252911 s
2019-11-29 16:52:55[ INFO](Logging.scala:54) Pruning directories with: 
2019-11-29 16:52:55[ INFO](Logging.scala:54) Post-Scan Filters: isnotnull(age#6L),(age#6L > 18)
2019-11-29 16:52:55[ INFO](Logging.scala:54) Output Data Schema: struct<age: bigint, name: string>
2019-11-29 16:52:55[ INFO](Logging.scala:54) Pushed Filters: IsNotNull(age),GreaterThan(age,18)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Code generated in 11.8699 ms
2019-11-29 16:52:56[ INFO](Logging.scala:54) Code generated in 8.9856 ms
2019-11-29 16:52:56[ INFO](Logging.scala:54) Block broadcast_2 stored as values in memory (estimated size 219.7 KB, free 895.9 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 8
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 5
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 17
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 23
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 12
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 16
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 11
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 29
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 10
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 21
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 28
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 13
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 20
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 24
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 19
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 9
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 14
2019-11-29 16:52:56[ INFO](Logging.scala:54) Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.6 KB, free 895.9 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Added broadcast_2_piece0 in memory on TKK-YXKJ:53030 (size: 20.6 KB, free: 896.4 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Created broadcast 2 from show at SqlParse.java:19
2019-11-29 16:52:56[ INFO](Logging.scala:54) Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-11-29 16:52:56[ INFO](Logging.scala:54) Removed broadcast_1_piece0 on TKK-YXKJ:53030 in memory (size: 5.4 KB, free: 896.4 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 25
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 22
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 18
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 6
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 7
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 26
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 15
2019-11-29 16:52:56[ INFO](Logging.scala:54) Cleaned accumulator 27
2019-11-29 16:52:56[ INFO](Logging.scala:54) Starting job: show at SqlParse.java:19
2019-11-29 16:52:56[ INFO](Logging.scala:54) Got job 1 (show at SqlParse.java:19) with 1 output partitions
2019-11-29 16:52:56[ INFO](Logging.scala:54) Final stage: ResultStage 1 (show at SqlParse.java:19)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Parents of final stage: List()
2019-11-29 16:52:56[ INFO](Logging.scala:54) Missing parents: List()
2019-11-29 16:52:56[ INFO](Logging.scala:54) Submitting ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19), which has no missing parents
2019-11-29 16:52:56[ INFO](Logging.scala:54) Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 895.9 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.8 KB, free 895.9 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Added broadcast_3_piece0 in memory on TKK-YXKJ:53030 (size: 5.8 KB, free: 896.4 MB)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2019-11-29 16:52:56[ INFO](Logging.scala:54) Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at show at SqlParse.java:19) (first 15 tasks are for partitions Vector(0))
2019-11-29 16:52:56[ INFO](Logging.scala:54) Adding task set 1.0 with 1 tasks
2019-11-29 16:52:56[ INFO](Logging.scala:54) Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8325 bytes)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Running task 0.0 in stage 1.0 (TID 1)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Reading File path: file:///D:/project/sparkTotal/jvm/java8/student, range: 0-97, partition values: [empty row]
2019-11-29 16:52:56[ INFO](Logging.scala:54) Code generated in 5.9612 ms
2019-11-29 16:52:56[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1). 1193 bytes result sent to driver
2019-11-29 16:52:56[ INFO](Logging.scala:54) Finished task 0.0 in stage 1.0 (TID 1) in 30 ms on localhost (executor driver) (1/1)
2019-11-29 16:52:56[ INFO](Logging.scala:54) Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-11-29 16:52:56[ INFO](Logging.scala:54) ResultStage 1 (show at SqlParse.java:19) finished in 0.040 s
2019-11-29 16:52:56[ INFO](Logging.scala:54) Job 1 finished: show at SqlParse.java:19, took 0.041944 s
2019-11-29 16:52:56[ INFO](Logging.scala:54) Invoking stop() from shutdown hook
2019-11-29 16:52:56[ INFO](AbstractConnector.java:318) Stopped Spark@61078690{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-11-29 16:52:56[ INFO](Logging.scala:54) Stopped Spark web UI at http://TKK-YXKJ:4040
2019-11-29 16:52:56[ INFO](Logging.scala:54) MapOutputTrackerMasterEndpoint stopped!
2019-11-29 16:52:56[ INFO](Logging.scala:54) MemoryStore cleared
2019-11-29 16:52:56[ INFO](Logging.scala:54) BlockManager stopped
2019-11-29 16:52:56[ INFO](Logging.scala:54) BlockManagerMaster stopped
2019-11-29 16:52:56[ INFO](Logging.scala:54) OutputCommitCoordinator stopped!
2019-11-29 16:52:56[ INFO](Logging.scala:54) Successfully stopped SparkContext
2019-11-29 16:52:56[ INFO](Logging.scala:54) Shutdown hook called
2019-11-29 16:52:56[ INFO](Logging.scala:54) Deleting directory C:\Users\Token\AppData\Local\Temp\spark-3e6cb6f5-027e-4806-a31d-8f31fcf7507c
2020-1-14 17:06:31[ERROR](ConfigurationManager.java:62) 配置属性为空，转为Integer发生异常
2020-1-14 17:07:53[ERROR](ConfigurationManager.java:62) 配置属性为空，转为Integer发生异常
2020-1-14 17:09:12[ERROR](ConfigurationManager.java:62) 配置属性为空，转为Integer发生异常
